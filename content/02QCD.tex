\chapter{Quantum Chromodynamics}
\section{QCD: The basics}
In the 1940s, a number of unstable, strongly interacting particles -- collectively referred to as hadrons -- were discovered. In 1964, Gell-Mann~\cite{Gell-Mann:1964ewy} and Zweig~\cite{Zweig:1964ruk, Zweig:1964jf} proposed the quark model, which interprets hadrons as composite objects built from fundamental spin-$\tfrac{1}{2}$ constituents known as \emph{quarks}. The six known quarks are organised into three generations -- light, intermediate, and heavy -- as listed in Table~\ref{table:quark-properties}. In this picture, hadrons fall into two classes: mesons ($q\bar q$) and baryons ($qqq$).
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Light  & Intermediate & Heavy & Charge \\ \hline
$u$ (up)   & $c$ (charm)   & $t$ (top) & $+\tfrac{2}{3}$    \\ \hline
$d$   (down)	& $s$ (strange)    & $b$ (bottom)  & $-\tfrac{1}{3}$  \\ \hline
\end{tabular}
\caption{Properties of the 6 known quarks. More details on the mass can be found in~\cite{ParticleDataGroup:2024cfk}.}
\label{table:quark-properties}
\end{table}

Quantum Chromodynamics (QCD) is an $\mathrm{SU}(3)$ non-Abelian gauge theory that governs the strong interaction. It describes how quarks are bound together to form hadrons, with the interaction mediated by gauge bosons known as gluons. Quarks and gluons are collectively referred to as \emph{partons} and carry a conserved charge called colour. Quarks transform in the fundamental representation of $\mathrm{SU}(3)$, with fields denoted by $q_a$ for $a = 1,2,3$, corresponding to the three colour labels: red, green, and blue. The associated antiquark fields are written as $\bar q^a$. Gluons, denoted by $\mathcal{A}^\mu_A$, transform in the adjoint representation of $\mathrm{SU}(3)$, where the index $A$ labels the eight colour degrees of freedom of the gauge group.\\ \\
The QCD Lagrangian density describes the dynamics of massless gluons and quarks of mass $m$:
\begin{equation}
\label{eq: L-QCD}
\mathcal{L}_{\mathrm{QCD}}
= \mathcal{L}_{\mathrm{classical}}
+ \mathcal{L}_{\mathrm{GF}}
+ \mathcal{L}_{\mathrm{ghost}}\,,
\end{equation}
where the classical contribution contains the kinetic and interaction terms for the quark and gluon fields:
\begin{equation}
\label{eq: L-Classical}
\mathcal{L}_{\mathrm{classical}}
= -\frac{1}{4} F_{\mu\nu}^{A} F^{\mu\nu}_{A}
+ \sum_{f=1}^{n_f} \bar{q}^f_a (i\slashed{D} - m)_{ab}\, q^f_b \,.
\end{equation}
Here $n_f$ denotes the number of quark flavours, which takes the value $n_f = 6$ in the Standard Model (see Table~\ref{table:quark-properties}). The gluon dynamics are encoded in the non-Abelian field-strength tensor
\begin{equation}
F_{\alpha\beta}^{A}
= \partial_\alpha A_\beta^A
- \partial_\beta A_\alpha^A
- g_s f^{ABC} A_\alpha^B A_\beta^C \,,
\end{equation}
where the strength of the interaction is governed by the strong coupling $g_s$ which can be expressed in terms of the coupling constant, 
\begin{equation}
    \alpha_s \equiv \frac{g_s^2}{4\pi}\,.
    \label{eq:coupling-constant}
\end{equation}
The covariant derivative is written using Feynman slash notation, $\slashed{D} = \gamma_\mu D^\mu$, with
\begin{equation}
(D_\mu)_{ab}
= \partial_\mu \delta_{ab}
+ ig_s (t^C A_\mu^C)_{ab}\,,
\end{equation}
where the gamma matrices satisfy the anti-commutation relation $\{\gamma^\mu,\gamma^\nu\} = 2 g^{\mu\nu}$. Throughout this work we adopt the metric convention $g^{\mu\nu} = (1,-1,-1,-1)$. The matrices $t^C$ denote the generators of the fundamental representation of $\mathrm{SU}(3)$. An explicit representation is given by the eight traceless and Hermitian Gell-Mann matrices, $\lambda^C$, such that
\begin{equation}
	t^C=\frac{1}{2}\lambda^C\,.
\end{equation}
These colour matrices satisfy the commutation relation
\begin{equation}
[t^A, t^B] = i f^{ABC} t^C\,,
\end{equation}
where $f^{ABC}$ are the structure constants of the $\mathrm{SU}(3)$ gauge group. In addition to the commutation relation above, the generators obey the identities
\begin{equation}
\begin{aligned}
\mathrm{Tr}(t^A t^B) &= T_R\, \delta^{AB}, \qquad T_R = \frac{1}{2}, \\
\sum_A t^{A}_{ab} t^{A}_{bc} &= C_F\, \delta_{ac}, \qquad C_F = \frac{4}{3}, \\
\sum_{A,B} f^{ABC} f^{ABD} &= C_A\, \delta^{CD}, \qquad C_A = 3.
\end{aligned}
\end{equation}
\\The second term in Eq.~\ref{eq: L-QCD} is the gauge-fixing term:
\begin{equation}
    \mathcal{L}_{\mathrm{GF}}
    = -\frac{1}{2\xi} \left( \partial^\mu A_\mu^{A} \right)^{2}\,.
\end{equation}
This term is required due to the local $\mathrm{SU}(3)$ gauge invariance of the QCD Lagrangian, which leads to redundant gauge degrees of freedom. The gauge-fixing term removes this redundancy, and the parameter $\xi$ specifies the choice of gauge; for example, $\xi = 1$ corresponds to Feynman gauge, while $\xi = 0$ corresponds to Landau gauge.
\\\\
The final term in Eq.~\ref{eq: L-QCD} is the ghost term,
\begin{equation}
\mathcal{L}_\mathrm{ghost} = \partial_\mu \eta^{A^\dagger}(D_{AB}^\mu\,\eta^B)\,,
\end{equation}
where $\eta^A$ are complex scalar fields known as Faddeev--Popov ghosts. These fields anti-commute and therefore obey Fermi statistics. Ghosts do not correspond to physical states; instead, they arise as a consequence of the gauge-fixing procedure in non-Abelian gauge theories.\\ \\
The Feynman rules derived from the QCD Lagrangian are shown in Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules}. The propagators follow from the kinetic terms of the Lagrangian, while the interaction terms give rise to the vertices. For brevity, the ghost Feynman rules are omitted, as they are not required for the calculations presented in this thesis.

\begin{figure}[h!]
\centering

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \diagram*{
        (a) -- [fermion, momentum={$p$}] (b),
    };
\end{feynman}
\node[left] at (a) {$a,i$};
\node[right] at (b) {$b,j$};
\node[right=1.0cm of b] {$=\; \delta^{ab}\dfrac{i}{(\slashed{p}-m+i\epsilon)_{ji}}$};
\end{tikzpicture}

\vspace{0.7cm}

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \diagram*{
        (a) -- [gluon, momentum={$p$}] (b),
    };
\end{feynman}
\node[left] at (a) {$A,\mu$};
\node[right] at (b) {$B,\nu$};
\node[right=1.0cm of b] {$=\; \delta^{AB}\dfrac{i}{p^{2}+i\epsilon}\!\left(-g_s^{\mu\nu}-(1-\xi)\dfrac{p^\mu\,p^\nu}{p^2+i\epsilon}\right)$};
\end{tikzpicture}

\caption{Feynman rules for the quark and gluon propagators.}
\label{fig:QCD-Propagator-Rules}
\end{figure}


\begin{figure}[h!]
\centering

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \vertex[above right=1.2cm and 0.8cm of b] (c);
    \vertex[below right=1.2cm and 0.8cm of b] (d);
    \diagram*{
        (a) -- [gluon] (b),
        (b) -- [fermion] (c),
        (b) -- [anti fermion] (d),
    };
\end{feynman}
\node[left] at (a) {$A,\mu$};
\node[right] at (c) {$c,j$};
\node[right] at (d) {$b,i$};
\node[right=1.5cm of b] {$=\; -ig_s\,(t^A)_{cb}\,(\gamma^\alpha)_{ji}$};
\end{tikzpicture}

\vspace{0.7cm}

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (v);
    \vertex[left=2cm of v] (a);
    \vertex[above right=1.3cm and 0.9cm of v] (b);
    \vertex[below right=1.3cm and 0.9cm of v] (c);

    \diagram*{
        (a) -- [gluon, momentum={$p$}] (v),
        (b) -- [gluon, momentum={$q$}] (v),
        (c) -- [gluon, momentum={$r$}] (v),
    };
\end{feynman}

\node[left] at (a) {$A,\mu$};
\node[above right] at (b) {$B,\nu$};
\node[below right] at (c) {$C,\gamma$};

\node[right=2.3cm of v] {
$\displaystyle
= -g_s\, f^{ABC}
\big[
(p-q)^\gamma g^{\mu\nu}
+ (q-r)^\mu g^{\nu\gamma}
+ (r-p)^\nu g^{\mu\gamma}
\big]
$
};

\end{tikzpicture}


\vspace{0.7cm}
\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (v);
    \vertex[above left=of v]  (A) {$A,\mu$};
    \vertex[below left=of v]  (B) {$B,\nu$};
    \vertex[above right=of v] (C) {$C,\gamma$};
    \vertex[below right=of v] (D) {$D,\delta$};

    \diagram*{
        (v) -- [gluon] (A),
        (v) -- [gluon] (B),
        (v) -- [gluon] (C),
        (v) -- [gluon] (D),
    };
\end{feynman}

\node[right=3.1cm of v] {
$\displaystyle
\begin{aligned}
&= -ig_s^2  \left[f^{EAC}f^{EBD}(g^{\mu\nu}g^{\gamma\delta}-g^{\mu\delta}g^{\nu\gamma})\right.\\
&\qquad\quad + f^{EAD}f^{EBC}(g^{\mu\nu}g^{\gamma\delta}-g^{\mu\gamma}g^{\nu\delta})\\
&\qquad\quad \left.+ f^{EAB}f^{ECD}(g^{\mu\gamma}g^{\nu\delta}-g^{\mu\delta}g^{\nu\gamma})\right]
\end{aligned}
$
};
\end{tikzpicture}


\caption{Feynman rules for the quark--gluon vertex, the three--gluon vertex, and the four--gluon vertex.}
\label{fig:QCD-Vertex-Rules}
\end{figure}

\reference{~\cite{Ellis:1996mzs}}
\newpage

\section{Perturbation Theory}
\label{sec:pert-theory}
With the QCD Lagrangian and corresponding Feynman rules established, we can now outline how calculations are performed in practice. Using the propagators and interaction vertices shown in Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules}, Feynman diagrams can be constructed. These diagrams represent the \emph{scattering (probability) amplitude} $\mathcal{M}$ for a given process and can be evaluated using the Feynman rules. \\ \\
From the structure of the interaction vertices, it is evident that either the emission of an additional gluon (a real correction) or the appearance of a loop (a virtual correction) within a Feynman diagram introduces additional powers of the strong coupling $\alpha_s$. This indicates that the scattering amplitude admits a perturbative expansion,
\begin{equation}
\label{eq:M-pert-theory}
    \mathcal{M}
    = \mathcal{M}^{(0)}
    + \frac{\alpha_s}{2\pi}\,\mathcal{M}^{(1)}
    + \left(\frac{\alpha_s}{2\pi}\right)^2\,\mathcal{M}^{(2)}
    + \dots\,,
\end{equation}
where $\mathcal{M}^{(0)}$ denotes the tree-level (classical) contribution, commonly referred to as the leading-order (LO) or Born term. The terms $\mathcal{M}^{(1)},\mathcal{M}^{(2)},\dots$ represent higher-order (quantum) corrections known as next-to-leading order (NLO), next-to-next-to-leading order (NNLO), and so on.  \\ \\ Since $\alpha_s$ becomes small at high energies (as discussed in the next section), higher-order contributions are increasingly suppressed in this regime. As a result, the perturbative expansion can be well approximated by retaining only the first few terms, yielding a \emph{fixed-order} (FO) prediction. This approach is known as perturbation theory, and its application to QCD is referred to as perturbative QCD (pQCD). Throughout this thesis, calculations are performed within the framework of pQCD.

\section{The running of the strong coupling $\alpha_s$}
\label{sec:running-coupling}
As noted in the previous section, pQCD relies on the strong coupling becoming small at high energies. This behaviour reflects the fact that $\alpha_s$ is not a fixed constant but instead \emph{runs} with the renormalisation scale $\mu_R$ -- an unphysical scale introduced by the renormalisation procedure, which will be discussed in the following section. The scale dependence of the coupling is governed by the renormalisation group equation
\begin{equation}
\label{eq:coupling-DE}
    \mu_R^2 \frac{\partial \alpha_s(\mu_R^2)}{\partial \mu_R^2} = \beta(\alpha_s)\,.
\end{equation}
The QCD $\beta$-function admits a perturbative expansion of the form
\begin{equation}
    \beta(\alpha_s) = -\!\left(\beta_0\,\alpha_s^2 + \beta_1\,\alpha_s^3 + \beta_2\,\alpha_s^4 + \cdots\right),
\end{equation}
with coefficients 
\begin{equation}
\begin{aligned}
    \beta_0 &= \frac{11 C_A - 4\,T_R\,n_f}{12\pi}\\[1em]
    \beta_1 &= \frac{17 C_A^2 - 5\,C_A\,n_f - 3\,C_F\,n_f}{2\pi\,(11 C_A - 2 n_f)}\\[1em]
    \beta_2 &= \frac{2857 C_A^3 + (54 C_F^2 - 615 C_F C_A - 1415 C_A^2)n_f + (66 C_F + 79 C_A)n_f^2}{288\pi^2\,(11 C_A - 2 n_f)}\,.
\end{aligned}
\end{equation}
It is worth noting that only $\beta_0$ and $\beta_1$ are renormalisation–scheme independent; the coefficients $\beta_2$ and higher depend on the choice of renormalisation scheme, taken here to be the $\overline{\mathrm{MS}}$ scheme (discussed later). Solving Eq.~\eqref{eq:coupling-DE} at leading order, using a reference scale $Q$, yields
\begin{equation}
\label{eq:scale-dependence}
    \alpha_s(\mu_R^2)
    = \frac{\alpha_s(Q^2)}
    {1 + \alpha_s(Q^2)\,\beta_0\,\ln\!\left(\tfrac{\mu_R^2}{Q^2}\right)}\, .
\end{equation}
From the sign of $\beta_0$ and the form of Eq.~\eqref{eq:scale-dependence}, the scale dependence of the strong coupling becomes apparent. As $\mu_R \to \infty$, the coupling decreases, and quarks and gluons behave increasingly like free particles. This behaviour is known as \emph{asymptotic freedom}, a regime in which pQCD provides an excellent approximation. Conversely, as $\mu_R$ becomes small and approaches a scale known as $\Lambda_{\mathrm{QCD}}$, the coupling grows large, signalling the breakdown of perturbation theory and the emergence of a strongly interacting regime in which quarks and gluons are confined into hadrons. This phenomenon is known as \emph{confinement} \\ \\
The running of the coupling has also been confirmed experimentally, as illustrated in Fig.~\ref{fig:strong-coupling}. Throughout this thesis, we will assume that we are working in the high-energy regime, thereby exploiting asymptotic freedom. 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/strong_coupling.pdf}
    \caption{Measurements of $\alpha_s$ as a function of the energy scale $Q$, taken from Ref.~\cite{ParticleDataGroup:2024cfk}.}
    \label{fig:strong-coupling}
\end{figure}
\reference{~\cite{Ellis:1996mzs, Campbell:2017hsr}}
\section{Divergences}
\label{sec:divergences}
While perturbation theory is very effective at high energies, it also introduces
certain difficulties in the form of divergences. In QCD, these divergences arise in two distinct forms:
\begin{itemize}
    \item \textbf{Ultraviolet (UV) divergences} arise in loop diagrams when the momentum of the
    virtual particle becomes large.
    \item \textbf{Infrared (IR) divergences} arise when a gluon emission becomes soft (low energy) or
    collinear to a hard (high energy) parton.
\end{itemize}
\subsection*{UV Divergences}
We begin by discussing UV divergences. One Feynman rule not shown in
Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules} is the rule associated
with loop diagrams. Each closed loop contributes an integration of the form
\begin{equation}
    \mathrm{loop} \;\longrightarrow\; \frac{d^Dq}{(2\pi)^D}\,,
\end{equation}
where $q^\mu$ denotes the momentum of the virtual particle running inside the loop, as
illustrated by the fermion bubble diagram shown in Fig.~\ref{fig:fermion-bubble}.
\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=2]
\begin{feynman}
    \vertex (a) at (-2,0) {$\mu$, a};
    \vertex (b) at ( 2,0) {$\nu$, b};
    \vertex (c) at (-0.8,0);
    \vertex (d) at ( 0.8,0);

    \diagram*{
        (a) -- [gluon, momentum=$p$] (c),
        (d) -- [gluon, momentum=$p$] (b),
        (c) -- [fermion, half left, looseness=1.5, momentum=$p+q$] (d),
        (d) -- [fermion, half left, looseness=1.5, momentum=$q$] (c),
    };
\end{feynman}
\end{tikzpicture}
\caption{Fermion bubble diagram illustrating a one-loop contribution to the gluon self-energy.}
\label{fig:fermion-bubble}
\end{figure}
Taking the quarks to be massless, as assumed throughout this thesis, and applying the
Feynman rules, the diagram gives rise to an integral of the form
\begin{equation}
    I = \int d^4 q \, \frac{N^{\mu\nu}}{q^2 (p+q)^2}\,,
\end{equation}
where $N^{\mu\nu}$ denotes a numerator whose explicit form is not required for the present
discussion. For large loop momenta, the integral reveals a UV divergence,
\begin{equation}
    I \sim \lim_{\Lambda \to \infty} \int_0^\Lambda \frac{dq}{q}
      \sim \lim_{\Lambda \to \infty} \ln \Lambda\,.
\end{equation}
Such divergences cannot be allowed to remain in the theory, and therefore a systematic method for handling them is required. This is achieved through a procedure known as \emph{regularisation}. Although several regularisation procedures  exist, in this thesis we use \emph{dimensional regularisation}~\cite{tHooft:1972tcz, Bollini:1972ui}. This method preserves both Lorentz and gauge invariance and, as will be discussed later, can also be applied to infrared divergences. The basic idea is to promote the space--time dimension to $d = 4 - 2\varepsilon$, with $\varepsilon < 0$, such that logarithmic divergences are replaced by poles in $\varepsilon$. \\ \\
Once these poles have been isolated, the next step is to remove them. This is achieved by redefining the parameters of the theory and introducing counterterms that cancel the divergent contributions, a procedure known as \emph{renormalisation}. Throughout this thesis, we work in the $\overline{\mathrm{MS}}$ renormalisation scheme, in which the counterterms
subtract not only the $1/\varepsilon$ poles but also the accompanying constants
$\ln 4\pi$ and $\gamma_E$ (the Euler–Mascheroni constant, $\gamma_E\approx0.5772$) that arise as a result of using dimensional regularisation. The renormalisation procedure introduces the renormalisation scale $\mu_R$, and consequently the strong coupling $\alpha_s$ acquires a dependence on this scale, as discussed in the previous section.\\
\reference{~\cite{Peskin:1995ev}}

\subsection*{IR Divergences}
Turning now to IR divergences, we consider the simplest QCD process,
$e^+e^- \rightarrow \mathrm{hadrons}$. At leading order, the cross section is obtained
by evaluating the partonic process $e^+e^- \rightarrow q\bar{q}$. This approach is
justified by quark--hadron duality: in the high-energy regime, the hadronic cross
section can be approximated sufficiently well by the corresponding partonic cross
section computed in perturbation theory \footnote{There are, however, known exceptions to this approximation; see Ref.~\cite{Shifman:2000jv}.}.
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}

            \vertex (e1) at (0,1) {\(e^-\)};
            \vertex (e2) at (0,-1) {\(e^+\)};

            \vertex at (1.5,0) (a);

           \vertex (b) at (3.5,0);

           \vertex (f1) at (4.8,1) {\(q\)};
            \vertex (f2) at (4.8,-1) {\(\overline{q}\)};
            \diagram* {
                (e1) -- [fermion] (a) -- [fermion] (e2),
                (a)  -- [photon, edge label=\(\gamma^*\)] (b),
                (b)  -- [fermion] (f1),
                (b)  -- [anti fermion] (f2),
            };

        \end{feynman}
    \end{tikzpicture}
\caption{Feynman diagram for the leading-order process \(e^+e^-\to\gamma^* \to q\bar{q}\).}
    \label{fig:photon-qq}
\end{figure}
\FloatBarrier
\noindent
\question{
\begin{enumerate}
	\item Quark-hardon duality was initially introduced by Poggio, Quinn and Weinberg - should this be cited here? I am thinking that I need a citation for this for quark-hadron duality itself along with the exceptions to it in Ref.~\cite{Shifman:2000jv}.
		\item Quark-hadron duality refers to \emph{inclusive} cross-sections - do I need to be 		explicit about this here?
\end{enumerate} 
} 
The resulting leading-order cross section is
\begin{equation}
	\sigma_{\mathrm{LO}}=\frac{4\pi\alpha^2}{s}N_c\sum_fQ_f^2\,,
\end{equation}
where $Q_f$ is the electric charge of a quark of flavour $f$, $N_c = 3$ is the number of quark colours, and $\alpha$ is the QED coupling constant. 

\noindent
To understand the structure of the IR divergences, we now consider the NLO contributions arising from real gluon emission, shown in Fig.~\ref{fig:photon-qqg}.
\begin{figure}[h]
\centering
\begin{minipage}{0.45\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}

        \vertex (e1) at (0,1) {\(e^-\)};
        \vertex (e2) at (0,-1) {\(e^+\)};

        \vertex (a) at (1.5,0);

        \vertex (b) at (3.5,0);

        \vertex (f1) at (4.8,1) {\(q\)};
        \vertex (f2) at (4.8,-1) {\(\overline{q}\)};

        \vertex at ($(b)!0.3!(f1)$) (m1);

        \vertex at ($(m1)+(1.2,-0.2)$) (g1) {\(g\)};

        \diagram*{
            (e1) -- [fermion] (a) -- [fermion] (e2),
            (a) -- [photon, edge label=\(\gamma^*\)] (b),

            (b) -- [fermion] (m1) -- [fermion] (f1),
            (b) -- [anti fermion] (f2),

            (m1) -- [gluon] (g1),
        };

    \end{feynman}
    \end{tikzpicture}

\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}

        \vertex (e1) at (0,1) {\(e^-\)};
        \vertex (e2) at (0,-1) {\(e^+\)};

        \vertex (a) at (1.5,0);

        \vertex (b) at (3.5,0);

        \vertex (f1) at (4.8,1) {\(q\)};
        \vertex (f2) at (4.8,-1) {\(\overline{q}\)};

        \vertex at ($(b)!0.3!(f2)$) (m2);

        \vertex at ($(m2)+(1.2,0.2)$) (g2) {\(g\)};

        \diagram*{
            (e1) -- [fermion] (a) -- [fermion] (e2),
            (a) -- [photon, edge label=\(\gamma^*\)] (b),

            (b) -- [fermion] (f1),
            (b) -- [anti fermion] (m2) -- [anti fermion] (f2),

            (g2) -- [gluon] (m2),
        };

    \end{feynman}
    \end{tikzpicture}
\end{minipage}
\caption{Feynman diagrams for the real-emission contributions to \(e^+e^- \to \gamma^* \to q\bar{q}g\) at NLO.}
\label{fig:photon-qqg}
\end{figure}
\FloatBarrier
\noindent
The corresponding real-emission contribution to the cross section is
\begin{equation}
\label{eq:qqg-real}
	\sigma^{q\bar{q}g}=\sigma_{\mathrm{LO}}\,\,C_F\,\frac{\alpha_s}{2\pi}\int_0^1dx_q\int_{1-x_q}^{1}dx_{\bar{q}}\,\,\frac{x_q^2+x_{\bar{q}}^2}{(1-x_q)(1-x_{\bar{q}})}\,,
\end{equation}
where the energy fractions are defined as 
\[
    x_i = \frac{2 p_i \cdot p}{s}\,, \qquad p=(p_q+p_{\bar{q}}+p_g)\,,
    \]
 and $s=(p_{e^+}+p_{e^-})^2$ is the centre-of-mass (CoM) energy squared. 
From the structure of the integrand, divergences arise in the following limits:
\begin{enumerate}
    \item \(x_q \to 1\) \emph{and} \(x_{\bar{q}} \to 1\): soft emission (\(E_g \to 0\));
    \item \(x_q \to 1\) \emph{or} \(x_{\bar{q}} \to 1\): collinear emission 
          (\(\theta_{\bar{q}g},\, \theta_{qg} \to 0\))\,,
\end{enumerate}
where $\theta_{qg}, \theta_{\bar{q}g}$ are the angles between the (anti) quark and gluon respectively.
These are infrared and collinear singularities, collectively referred to as IR (or IRC) divergences. Using dimensional regularisation to isolate these singularities, Eq.~\ref{eq:qqg-real} becomes
\begin{equation}
    \sigma^{q\bar{q}g}
    = \sigma_{\mathrm{LO}}\, \frac{\alpha_s}{2\pi}\,
      \frac{C_F}{\Gamma(1-\varepsilon)}
      \left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}
      \left(
          \frac{2}{\varepsilon^2}
        + \frac{3}{\varepsilon}
        - \pi^2
        + 8
        + \mathcal{O}(\varepsilon)
      \right).
\end{equation}
At this order, the cross section also receives a contribution from the virtual correction, shown in Fig.~\ref{fig:photon-qq(g)}.
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}
            \vertex (e1) at (0,1)  {\(e^-\)};
            \vertex (e2) at (0,-1) {\(e^+\)};
            
  	    \vertex (a) at (1.5,0);
	    \vertex (b) at (3.5,0);
	    
        \vertex (f1) at (4.8,1) {\(q\)};
        \vertex (f2) at (4.8,-1) {\(\overline{q}\)};
            \vertex at ($(b)!0.6!(f1)$) (mid1);
            \vertex at ($(b)!0.6!(f2)$) (mid2);

            \diagram*{
                (e1) -- [fermion] (a) -- [fermion] (e2),
                (a)  -- [photon, edge label=\(\gamma^*\)] (b),
                (b)  -- [fermion]      (f1),
                (b)  -- [anti fermion] (f2),
                (mid2) -- [gluon] (mid1),
            };
        \end{feynman}
    \end{tikzpicture}
  \caption{Feynman diagram for the virtual contribution to $e^+e^- \to \gamma^* \to q\bar{q}$ at NLO.}    \label{fig:photon-qq(g)}
\end{figure}

\FloatBarrier
\noindent
\add{Tiny formatting on gluon connecting to the upper leg - unsure how to resolve.}

\noindent
The virtual correction produces poles with precisely the same structure but opposite sign:
\begin{equation}
    \sigma^{q\bar{q}(g)}
    = \sigma_{\mathrm{LO}}\, \frac{\alpha_s}{2\pi}\,
      \frac{C_F}{\Gamma(1-\varepsilon)}
      \left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}
      \left(
         -\frac{2}{\varepsilon^2}
         -\frac{3}{\varepsilon}
         + \pi^2
         - 8
         + \mathcal{O}(\varepsilon)
      \right).
\end{equation}
Adding the real and virtual contributions yields a finite NLO correction,
\[
    \sigma_{\mathrm{NLO}}
    = \sigma^{q\bar{q}g} + \sigma^{q\bar{q}(g)}
    = \sigma_{\mathrm{LO}}\, \frac{\alpha_s}{2\pi}\,
      \frac{C_F}{\Gamma(1-\varepsilon)}
      \left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}
      \left(\frac{3}{2} + \mathcal{O}(\varepsilon)\right).
\]
Taking the limit \(\varepsilon \to 0\), the total cross section up to NLO is
\begin{equation}
    \sigma
    = \sigma_{\mathrm{LO}}
      \left(1 + \frac{\alpha_s}{2\pi}\,\frac{3}{2} C_F
      + \mathcal{O}(\alpha_s^2)\right).
\end{equation}
The cancellation of singularities between the real and virtual diagrams is a direct consequence of the \emph{KLN theorem}~\cite{Kinoshita:1962ur, Lee:1964is}, which guarantees that IR divergences cancel between real and virtual contributions order by order in perturbation theory for any process, provided one sums over all initial and final states. \\ \\
\reference{~\cite{Ellis:1996mzs, Luisoni:2015xha, Schwartz:2014sze} }

\section{Soft and collinear factorisation of $|\mathcal{M}_m|^2$}
\label{sec:M-factorisation}
We now consider the general structure of infrared singularities by introducing
the partonic cross section for a generic $2\rightarrow m$ hard-scattering
process,
\[
    p_a + p_b \rightarrow p_1 + \cdots + p_m\,.
\]
The corresponding partonic cross section is given by
\begin{equation}
\label{eq:2-to-m-xsec}
   \hat{ \sigma}= \frac{1}{2s}\int d\Phi^{(m)}(p_1,\ldots,p_m)\,|\mathcal{M}_m(p_a,p_b; p_1,\ldots,p_m)|^2\,F_J^{(m)}(p_1,\ldots,p_m)\,,
\end{equation}
where the individual components are defined as follows:
\begin{itemize}
	\item $d\Phi^{(m)}$ is the $m$-parton phase space,
\begin{equation}
	d\Phi^{(m)}=(2\pi)^4\delta^{(4)}\left(p_a+p_b-\sum_{i=1}^{m}p_i\right)\prod_{i=1}^{m}\,\frac{d^3p_i}{(2\pi)^3\,2E_i}\,.
\end{equation}
\item $\mathcal{M}_m$ is the scattering amplitude for the $2\!\rightarrow\! m$ process. It admits the perturbative expansion shown in Eq.~\ref{eq:M-pert-theory}. Its modulus squared is written as
    \[
        |\mathcal{M}_m|^2 = \langle \mathcal{M}_m | \mathcal{M}_m \rangle\,,
    \]
    which implicitly sums over the colour and spin degrees of freedom of the $m$ final-state particles.
\item $F_J^{(m)}$ is the \emph{jet function}, which specifies the observable under consideration.
 Depending on the choice of $\Theta$–functions, $\delta$–functions, or numerical
factors, it can describe: cross-sections, differential cross sections or expectation values respectively. For $F_J^{(m)} = 1$, Eq.~\ref{eq:2-to-m-xsec} reduces to the total cross-section.
\end{itemize}
\add{A reference for this section - particularly Eq.~\ref{eq:2-to-m-xsec}.} \\\\
With the general form of the partonic cross section established, we now turn to the behaviour
of the squared scattering amplitude $|\mathcal{M}_m|^2$.  
In the soft and collinear limits, this quantity factorises into a remarkably simple and universal form. The relevant expressions are summarised below.
\subsection*{Soft limit}
Suppressing the initial–state momenta $(p_a,p_b)$ for brevity, the squared matrix
element for the emission of an additional soft parton of momentum $q$ behaves as
\begin{equation}
    |\mathcal{M}_{m+1}^{(0)}(q,p_1,\ldots,p_m)|^2
    \simeq
    -4\pi\alpha_s
    \sum_{i,j=1}^{m}
        S_{ij}(q)\,
        \big\langle
            \mathcal{M}_m^{(0)}(p_1,\ldots,p_m)
        \big|
            \mathbf{T}_i \cdot \mathbf{T}_j
        \big|
            \mathcal{M}_m^{(0)}(p_1,\ldots,p_m)
        \big\rangle,
\end{equation}
where the colour operators satisfy
\begin{equation}
\begin{aligned}
    \mathbf{T}_i \cdot \mathbf{T}_j &= \mathbf{T}_j \cdot \mathbf{T}_i \qquad (i\neq j),\\[4pt]
    \mathbf{T}_i^2 &= C_i \qquad (C_i = C_F \text{ for a quark, } C_A \text{ for a gluon}),
\end{aligned}
\end{equation}
and the eikonal factor
\[
    S_{ij}(q) = \frac{p_i \cdot p_j}{(p_i \cdot q)(p_j \cdot q)}
\]
encodes the soft dynamics of QCD.

\subsection*{Collinear limit}

When two partons $i$ and $j$ become collinear, the squared matrix element factorises as
\begin{equation} 
|\mathcal{M}_{m+1}^{(0)}(p_1,\cdots p_i, p_j, \cdots p_{m+1})|^2\simeq4\pi\alpha_s\bra{\mathcal{M}_{m}^{(0)}(p_1,\cdots p_{ij}, \cdots p_m)}\hat{\mathbf{P}}^{(0)}_{ij}(z,k_\perp;\epsilon)\ket{\mathcal{M}_{m}^{(0)}(p_1,\cdots p_{ij}, \cdots p_m)}\,.
\end{equation}
The operators $\hat{\mathbf{P}}^{(0)}_{ij}$ are the fully \emph{regularised} form of the Altarelli-Parisi splitting function, whose explicit forms are \question{Should we be saying these regularised AP functions are \emph{produced} by the operator?}
\begin{equation}
\begin{aligned}
\label{eq:AP-functions}
	&\hat{P}_{q\bar{q}}^{(0)}(z,k_\perp;\epsilon)=\hat{P}_{\bar{q}q}^{(0)}(z,k_\perp;\epsilon)=T_R\left[-g^{\mu\nu}+4z(1-z)\frac{k_\perp^{\mu}k_\perp^{\nu}}{k_\perp^2}\right]\\
	&\hat{P}_{qg}^{(0)}(z,k_\perp;\epsilon)=\hat{P}_{{\bar{q}}g}^{(0)}(z,k_\perp;\epsilon)=\delta^{ss'}C_F\left[\frac{1+z^2}{1-z}-\epsilon(1-z)\right]\\
	&\hat{P}_{gq}^{(0)}(z,k_\perp;\epsilon)=\hat{P}_{g{\bar{q}}}^{(0)}(z,k_\perp;\epsilon)=\delta^{ss'}C_F\left[\frac{1+(1-z)^2}{z}-\epsilon z\right]\\
	&\hat{P}_{gg}^{(0)}(z,k_\perp;\epsilon)=2C_A\left[-g^{\mu\nu}\left(\frac{z}{1-z}+\frac{1-z}{2}\right)-2(1-\epsilon)z(1-z)\frac{k_\perp^{\mu}k_\perp^{\nu}}{k_\perp^2}\right]\,,
\end{aligned}
\end{equation}
where $s,s'$ denote the spins of the two partons.

\noindent
To derive these expressions, it is convenient to employ a Sudakov decomposition for the two collinear momenta,
\begin{equation}
\begin{aligned}
    p_i^\mu &= z_i\, p^\mu + k_\perp^\mu
               - \frac{k_\perp^2}{z_1}\,\frac{n^\mu}{2p\cdot n}, \\
    p_j^\mu &= z_j\,p^\mu - k_\perp^\mu
               - \frac{k_\perp^2}{z_j}\,\frac{n^\mu}{2p\cdot n},
\end{aligned}
\end{equation}
where $z_i+z_j=1$ are the longitudinal momentum fractions, $p^\mu$ and $n^\mu$ are light-like reference vectors, $k_\perp^\mu$ is transverse to both, and the collinear limit corresponds to $k_\perp^\mu \to 0$. \\ \\
\question{Should there be a discussion of subtraction/slicing here?}\\
\reference{~\cite{Luisoni:2015xha, Schwartz:2014sze} }

\section{IRC Safety} 
\label{sec:IRC}
In Sec.~\ref{sec:divergences} we saw, through the explicit NLO calculation of $e^{+}e^{-}\to q\bar q$, that the IR singularities from the real and virtual  contributions cancel, yielding a finite result. This relies on the fact that the total cross section is an \emph{inclusive} observable, for which $F_J^{(m)} = 1$  for $m$ final-state particles (see Sec.~\ref{sec:M-factorisation}). \\ \\
For more general observables, such a cancellation is not guaranteed. To obtain finite predictions order by order in perturbation theory, the observable must be \emph{infrared and collinear safe} (IRC safe). An IRC safe observable is one whose value is insensitive to the emission of an 
additional soft and/or collinear parton. This requirement can be expressed in terms of the jet function as
\begin{equation}
\begin{aligned}
F_J^{(m+1)}(p_1,\ldots,p_i,\ldots,p_{m+1})
&\;\longrightarrow\;
F_J^{(m)}(p_1,\ldots,\cancel{p_i},\ldots,p_{m+1})\,,
\qquad &&E_i \to 0, \\[6pt]
F_J^{(m+1)}(p_1,\ldots,p_i,p_j,\ldots,p_{m+1})
&\;\longrightarrow\;
F_J^{(m)}(p_1,\ldots,\cancel{p_i},\cancel{p_j},p_{ij},\ldots,p_{m+1})\,,
\qquad &&p_i \parallel p_j\,,
\end{aligned}
\label{eq:IRC-safety}
\end{equation}
where a diagrammatic representation of IRC safety is shown in Fig.~\ref{fig:IRC_safety}. 
\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=2]
\begin{feynman}

    \vertex (a) at (-1, 0.6) {\(p_a\)};
    \vertex (b) at (-1,-0.6) {\(p_b\)};

    \vertex[blob, minimum size=0.8cm] (H) at (0,0) {\(\mathcal{H}\)};

    \vertex (p1) at (1.5, 1.2) {\(p_1\)};
    \vertex (pj) at (1.5, 0.4) {\(p_j\)};  
    \vertex (pm) at (1.5,-1.0) {\(p_{m}\)};

    \vertex (x) at (0.72, 0.2);
    
    \vertex (pi) at (1.5, 0.65) {\(p_i\)};

    \diagram*{
        (a) -- [fermion] (H) -- [fermion] (p1),
        (b) -- [fermion] (H) -- [fermion] (pm),

        (H) -- [fermion] (pj),
        
    };


    \draw[gluon] (x) -- (pi);


    \node at (1.5, 0.9) {\(\cdots\)};
    \node at (1.5, -0.3) {\(\cdots\)};
\node[
    draw=black!30,
    fill=gray!5,
    rounded corners=3pt,
    font=\scriptsize,
    inner sep=4pt
] at (3.2,0.50)
{
    \shortstack{$F_J^{(m+1)}(\Phi^{(m+1)}) \;\longrightarrow\; F_J^{(m)}(\Phi^{(m)})$\\[2pt]
                $\text{if } E_i \to 0 \;\text{or}\; p_i \parallel p_j$}
};


\end{feynman}
\end{tikzpicture}
\caption{Diagrammatic representation of a $2\to m$ hard scattering process, $\mathcal{H}$, with an additional soft or collinear emission $p_i$.}
\label{fig:IRC_safety}
\end{figure}

\FloatBarrier
\noindent
We emphasise that although Eq.~\ref{eq:IRC-safety} is written for a single additional parton, the same behaviour holds for any number of additional soft/collinear partons. From this definition it follows immediately that inclusive observables with $F_J^{(m)} = 1$ are IRC safe. Other examples include event-shape variables (event-shapes), which will be discussed in Chapter~4. A simple example of an IRC-unsafe observable is the number of final-state partons. \\ \\
Although IRC safety ensures finite results at every order in perturbation theory, it does not guarantee a well-behaved perturbative expansion. Many \emph{exclusive} observables, despite being IRC safe, receive large logarithmic contributions which originate from emissions in the soft and/or collinear regions. These logarithms can spoil the convergent nature of the perturbative expansion and must be \emph{resummed}. Resummation techniques will be the focus of Chapters~4 and~5.\\ 
\question{
\begin{enumerate}
\item In this sense is the KLN theorem only for inclusive observables, where the idea of inclusivity comes from the fact that there will be a finite result at every order of perturbation theory \emph{provided} we sum over all initial and final states?
\item In this sense, exclusive observables are the only observables those that give rise to large logarithms?
\end{enumerate}}
\noindent
\reference{~\cite{Campbell:2017hsr, Luisoni:2015xha, Banfi:2016yyq}}

\section{The full picture: high-energy collisions}
Up to this point, the discussion has largely focused on physics at the parton level.
In particular, we have relied on concepts such as quark--hadron duality (see Sec.~\ref{sec:divergences}) to relate partonic cross-sections to hadronic observables, and have worked predominantly in the high-energy regime, where asymptotic freedom (see Sec.~\ref{sec:running-coupling}) allows the use of  perturbative QCD. \\ \\
In realistic collider experiments, however, the situation is significantly more complex.
Consider, for example, a hadronic collision at the LHC. The incoming particles are hadrons rather than partons, and the final-state particles observed in the detector consist of hadrons produced at energy scales far below that of the hard interaction. As a result, a complete description of a high-energy collision necessarily involves physics beyond the perturbative regime. \\ \\
The aim of this section is to outline the various stages of a high-energy hadronic collision. To illustrate this, we refer to Fig.~\ref{fig:high-energy-event}, produced by the \textsc{sherpa} collaboration in Ref.~\cite{Gleisberg:2008ta}, which shows a $t\bar t h$ event produced by a proton-proton collision. 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/High-energy-event.jpeg}
    \caption{Pictorial representaion of a $t\bar{t}h$ event produced in a high-energy hadronic collision, taken from Ref.~\cite{Gleisberg:2008ta}}.
    \label{fig:high-energy-event}
\end{figure}
Since the initial collision occurs at high energies and the energy of the system decreases as the event evolves towards hadronisation, it is natural for us to organise the discussion according to the relevant energy scale $Q$.
\subsection*{Hard scattering $(Q \gg \Lambda_{\mathrm{QCD}})$}
At the highest energy scale, the dynamics of the collision are governed by the hard scattering, represented by the central red blob in Fig.~\ref{fig:high-energy-event}. In this process, two partons, denoted $p_i$ and $p_j$, are extracted from the incoming protons $P_1$ and $P_2$ and undergo a short-distance interaction. The partonic content of the proton is encoded in parton distribution functions (PDFs), $f_{i,P_1}(x_1,\mu_F^2)$, which give the probability of finding a parton of type $i$ carrying a longitudinal momentum fraction $x_1$ of the proton $P_1$ at the factorisation scale~$\mu_F$.  PDFs are non-perturbative functions which are extracted from experimental data but their dependence on the scale $\mu_F$ is governed by perturbative QCD through the Dokshitzer--Gribov--Lipatov--Altarelli--Parisi (DGLAP) evolution equations~\cite{Gribov:1972ri,Dokshitzer:1977sg,Altarelli:1977zs},
\begin{equation}
	\frac{df_{i,P_1}(x_1,\mu_F^2)}{d\mu_F^2}=\sum_{j}\int_{x_1}^1dz\,\frac{\alpha_s}{2\pi}P_{ij}(z,\mu_F^2)f_j\left(\frac{x_1}{z},\mu_F^2\right)\,,
\end{equation}
where the splitting functions $P_{ij}(z)$ admit a perturbative expansion:
\begin{equation}
	P_{ij}(z,\mu_F^2) = P_{ij}^{(0)}(z)+\frac{\alpha_s}{2\pi} P_{ij}^{(1)}(z)+\dots\,.
\end{equation}
At leading order, the Altarelli-Parisi splitting functions (see Eq.~\ref{eq:AP-functions} for fully regularised forms) are given by \question{The notation of $\hat{P}_{ij}$ for fully regularised and $P_{ij}$ for normal is OK?}
\begin{equation}
\begin{aligned}
&P_{q\bar{q}}^{(0)}(z)=C_F\left[\frac{1+z^2}{(1-z)_+}+\frac{3}{2}\delta(1-z)\right]\,,\\
&P_{qg}^{(0)}(z)=T_R\left[z^2+(1-z)^2\right]\,,\\
&P_{gq}^{(0)}(z)=C_F\left[\frac{1+(1-z)^2}{z}\right]\,,\\
&P_{gg}^{(0)}(z)=2C_A\left[\frac{z}{(1-z)_+}+\frac{1-z}{z}+z(1-z)\right]+\delta(1-z)\frac{11C_A-4T_Rn_f}{6}\,.
\end{aligned}
\end{equation}
The factorisation scale $\mu_F$ separates long- and short-distance physics.
Radiation with transverse momentum below $\mu_F$ is absorbed into the PDFs and treated as part of the proton structure, while harder emissions are included explicitly in the partonic cross section. \\ \\ 
The hard interaction produces the primary particles of the event, in this case a $t\bar{t}h$ system, indicated by the smaller red blobs in Fig.~\ref{fig:high-energy-event}. Since the energy scale $Q$ is much larger than $\Lambda_{\mathrm{QCD}}$, predictions at this stage can be reliably obtained using fixed-order perturbation theory (see Sec.~\ref{sec:pert-theory}). Such calculations are typically provided by matrix-element generators, for example \textsc{MadGraph}~\cite{Alwall:2014hca} and \textsc{MCFM}~\cite{Campbell:1999ah,Campbell:2011bn,Campbell:2019dru}.


\subsection*{QCD evolution $(Q \gtrsim \Lambda_{\mathrm{QCD}})$}
Following the hard scattering, the coloured partons produced in the event undergo further QCD radiation, illustrated by the red quark and gluon propagators in Fig.~\ref{fig:high-energy-event}. This radiation is dominated by soft and collinear emissions, which for many observables give rise to logarithmically enhanced contributions (see Sec.~\ref{sec:IRC}). When such logarithms become large, fixed-order perturbation theory is no longer sufficient, and dedicated techniques are required to obtain reliable results in the perturbative regime. The accuracy of these techniques is typically characterised in terms of logarithmic accuracy, such as leading logarithmic (LL), next-to-leading logarithmic (NLL), and so on. Common approaches include:
\begin{itemize}
	\item \emph{Parton showers}, which model the
	soft and collinear emissions down to the hadronisation scale. Well-known examples
	include: \textsc{pythia}~\cite{Bierlich:2022pfr}, \textsc{herwig}~\cite{Bahr:2008pv, Bellm:2015jjp}, and \textsc{PanScales}~\cite{vanBeekveld:2023ivn}. While \textsc{pythia} and \textsc{herwig} parton showers have both achieved an LL accuracy, the \textsc{PanScales} parton shower has demonstrated NLL accuracy for a broad class of observables in both hadronic collisions~\cite{vanBeekveld:2022zhl, vanBeekveld:2022ukn} and deep-inelastic scattering~\cite{vanBeekveld:2023chs}, with ongoing work aimed at extending this to higher logarithmic accuracy.
	\item \emph{Resummation}, where logarithmically enhanced contributions from soft and
	collinear radiation are resummed to all orders in perturbation theory. Semi-numerical
	resummation frameworks such as \textsc{CAESAR}~\cite{Banfi:2004yd} and \textsc{ARES}~\cite{Banfi:2014sua} fall into this
	category. For $e^+e^-$ observables, resummation is known up to next-to-next-to-leading
	logarithmic (NNLL) accuracy~\cite{Arpino:2019ozn}, while hadronic collisions are currently known up to NLL. \question{which citation do we use for NLL hadronic collisions for ARES - there are many to choose from - is there a particular one?}
	The work presented in Chapter~5 focuses on extending the \textsc{ARES} framework to
	hadronic collisions at NNLL accuracy.
		\item \emph{Effective field theory} approaches, most notably soft-collinear effective
	theory (SCET)~\cite{Bauer:2000ew, Bauer:2000yr, Bauer:2001ct, Bauer:2001yt} which describe soft and collinear degrees of freedom through an
	observable-dependent factorisation formula. In this framework, the relevant dynamics
	are encoded in separate hard, collinear, soft, and jet functions, allowing resummation to
	be performed analytically \question{SCET is fully analytical?} for a range of observables, in some cases up to $\mathrm{N^3LL}$
	accuracy as seen in Ref.~\cite{Abbate:2010xh}. \question{There are many papers on observables with high accuracy - I presumed, since this is one Iain Stewart's papers it was safe to cite this?} 
\end{itemize}

\subsection*{Hadronisation ($Q \sim \Lambda_{\mathrm{QCD}}$)}
As the energy scale of the event approaches $\lambda_{\mathrm{QCD}}$,  the confinement effects dominate and hadronisation occurs. In this regime, the coloured partons produced by the hard scattering and subsequent QCD evolution (light green blobs in Fig.~\ref{fig:high-energy-event}) are transformed into colour-singlet hadrons (dark green blobs). These primary hadrons subsequently decay into long-lived particles (smaller dark green blobs) that are ultimately observed in the detector. Experimentally, these particles appear predominantly in the form of \emph{jets}, i.e.\ collimated sprays of hadrons. Jet clustering and its implications will be discussed in the next section. Hadronisation occurs in the non-perturbative regime and therefore cannot be calculated from first principles within QCD. Its effects are therefore modelled using numerical models. \question{I see that there are a lot of references for what models in the black book and~\cite{Gleisberg:2008ta} - however am unsure if these are out of date now.} 
\\ \\ 
The three stages described above capture the main features of the QCD dynamics in a high-energy hadronic collision, but several additional ingredients contribute to the structure of a realistic event. Electromagnetic radiation, shown as yellow lines in Fig.~\ref{fig:high-energy-event}, may occur at any stage of the process. In addition, secondary semi-hard interactions between the proton remnants give rise to the \emph{underlying event}, represented by the purple blob in Fig.~\ref{fig:high-energy-event}. These interactions generate further radiation and hadrons, however are not described by standard QCD factorisation and require modelling. \add{Find a reference for this modelling.} \\ \\
Finally, prior to the hard interaction, the incoming partons may radiate, leading to \emph{initial-state radiation}. This radiation evolves down to the hadronisation scale and contributes to the final-state hadrons (dark green blobs). The light blue ovals in Fig.~\ref{fig:high-energy-event} represent the beam remnants: the fragments of the incoming protons that do not participate in the hard collision.

\subsection*{The QCD Factorisation Formula}
To relate the partonic dynamics discussed so far to experimentally measured hadronic cross sections, we can employ the QCD factorisation formula,
\begin{equation}
\label{eq:factorisation-formula}
	\sigma(P_1,P_2)=\sum_{i,j}\int_0^1dx_1\,dx_2\,f_{i,P_1}(x_1,\mu_F^2)\,f_{j,P_2}(x_2,\mu_F^2)\,\hat{\sigma}_{ij}(\alpha_s(\mu_R^2),\mu_R^2,\mu_F^2)+\mathcal{O}\left(\frac{\Lambda_{\mathrm{QCD}}^2}{Q^2}\right)\,.
\end{equation}
Here $f_{i,P_1}$ and $f_{j,P_2}$ are the PDFs introduced earlier, and the integration runs over the momentum fractions carried by the partons inside the incoming hadrons. The sum over $i,j$ accounts for all possible parton flavours,
while $\hat{\sigma}_{ij}$ is the corresponding partonic cross section. \\ \\
Equation~\ref{eq:factorisation-formula} is referred to as a factorisation formula because it separates the hadronic cross section into two distinct components: the non-perturbative PDFs, which encode the partonic structure of the incoming hadrons, and the perturbatively calculable partonic cross section $\hat{\sigma}_{ij}$. The power-suppressed term $\mathcal{O}\!\left(\Lambda_{\mathrm{QCD}}^{2}/Q^{2}\right)$ reflects the fact that this separation is valid only in the high-energy limit. \\ \\
\reference{~\cite{Ellis:1996mzs, Banfi:2016yyq}}
\section{Jet Physics}
As described above, jets appear as highly collimated sprays of hadrons resulting from the hadronisation of energetic quarks and gluons produced in high-energy processes. They are among the most frequently observed objects in proton–proton collisions at the LHC and are complex, messy, and inherently ambiguous objects. To be able to describe them in a well-defined and reproducible way, we must introduce a \emph{jet definition}, which consists of the following components:
\begin{enumerate}
\item a \emph{jet algorithm}: a systematic procedure for grouping final-state particles into jets and determining the number of jets present in an event, i.e.\ a set of rules that cluster particles into a given jet;
\item the algorithm's \emph{parameters}: these specify the proximity required between two particles for them to be recombined into a single entity belonging to the same jet;
\item a \emph{recombination scheme}: this defines how the momenta of two particles are combined to form the momentum of the new clustered particle — the most commonly used being the $E$-scheme, , which is a four-momentum sum, i.e.\ $p_i^\mu + p_j^\mu = p_k^\mu$.
\end{enumerate}
In the next subsection, we discuss the jet algorithm and its input parameters in more detail. 
\reference{~\cite{Schwartz:2014sze, Campbell:2017hsr, Banfi:2016yyq, Salam:2010nqg}}

\subsection{Jet Algorithm}
In 1990, there was significant discussion within the high-energy physics community about how jets should be properly defined. To address this, a group of physicists formulated a set of requirements that a well-defined jet algorithm should satisfy, outlined in a document known as the \emph{Snowmass Accord}~\cite{Huth:1990mi}. The criteria are as follows:
\begin{enumerate}
    \item Simple to implement in an experimental analysis;
    \item Simple to implement in a theoretical calculation;
    \item Defined at any order in perturbation theory;
    \item Yields a finite cross section at any order in perturbation theory;
    \item Yields a cross section that is relatively insensitive to hadronisation effects.
\end{enumerate}
IRC safety ensures that jets defined at the detector, hadron, and parton levels are essentially equivalent, thereby satisfying the final three requirements outlined above. For IRC-safe observables, the effects of hadronisation are suppressed by inverse powers of the energy scale used in the process. Consequently, at higher energies, the correspondence between hadronic and partonic observables becomes increasingly accurate. \add{Link this back to quark-hadron duality allows quarks=hadrons at high-energies.} 
Overall, these requirements allow us to regard jets as well-defined objects whose properties can be either determined by their constituent hadrons or underlying partons. This enables direct comparison between experimental measurements and theoretical calculations at the parton level. \\ \\
A wide variety of jet algorithms exist, each with its own advantages and limitations. The choice of algorithm depends on the specific physics question being addressed and the type of information one seeks to extract from an event. In general, jet algorithms can be divided into two broad classes: \emph{sequential recombination algorithms} and \emph{cone algorithms}:
\begin{itemize}
    \item \textbf{Cone algorithms:} These group particles within a fixed radius $R$ in $(\eta,\phi)$ space, such that the particles whose transverse energy deposits fall inside the circular region are clustered into a jet. In three dimensions, these regions appear as cones. Different implementations vary in how they search for and define these cones. Cone algorithms are often described as \emph{top-down} algorithms.

    \item \textbf{Sequential recombination algorithms:} These iteratively cluster the closest particles according to a chosen distance measure until a stopping criterion is reached. Variations arise from different definitions of the distance measure (e.g.\ relative transverse momentum or angular separation between particles) and from the choice of stopping condition. Sequential recombination algorithms are often referred to as \emph{bottom-up} algorithms.
\end{itemize}
In this thesis, we focus exclusively on sequential recombination algorithms. The following sections discuss several of these algorithms to provide background for the new DIS algorithm introduced in Chapter~\ref{chapter: DIS}. For a comprehensive review of jets and jet algorithms across different processes, see Ref.~\cite{Salam:2010nqg}.\\ \\
\reference{~\cite{Banfi:2016yyq},~\cite{Salam:2010nqg}.}


\subsection{Jet Algorithms for $e^+e^-$ Collisions}
\label{subsec: e+e-}
Jet algorithms for electron–positron collisions follow a common iterative clustering procedure. Each pair of particles is assigned a \emph{distance measure}, $d_{ij}$, which determines how closely they are related. The closest pair is iteratively recombined until all remaining objects are separated by more than the chosen \emph{resolution parameter}, $d_{\mathrm{cut}}$.
This framework forms the basis of the JADE and Durham algorithms, while the Cambridge algorithm extends it by introducing an additional \emph{ordering variable}, $v_{ij}$, as discussed in the following sections.

\subsubsection{The JADE algorithm}
The first sequential recombination algorithm was introduced by the JADE Collaboration in 1988in Ref.~\cite{JADE:1988xlj} and is defined as follows:
\begin{enumerate}
    \item \textbf{Define a resolution parameter} $d_{\mathrm{cut}}$.
    \item \textbf{Compute the distance measure} for every pair of particles $i$ and $j$:
    \begin{equation}
        \label{eq:yij-jade}
        d^{\mathrm{JADE}}_{ij} = \frac{2E_iE_j(1 - \cos\theta_{ij})}{Q^2}\,,
    \end{equation}
    where $Q$ is the total centre-of-mass energy, $E_i$ is the energy of particle $i$, and $\theta_{ij}$ is the angle between particles $i$ and $j$.
    \item \textbf{Identify the smallest $d_{ij}$ value.} If this minimum satisfies $d_{ij} < d_{\mathrm{cut}}$, the two particles are recombined into a pseudo-particle according to the chosen recombination scheme.
    \item \textbf{Repeat the procedure} from step 2 until all remaining pairs satisfy $d_{ij} > d_{\mathrm{cut}}$. The remaining objects are then defined as jets.
\end{enumerate}
A drawback of the JADE algorithm is its tendency to cluster soft pairs of gluons that are widely separated in angle. This can lead to situations where a hard parton is incorrectly merged with a soft gluon that was not emitted from it, as shown in Fig.~\ref{fig:JADE}. Physically speaking, a jet should constitute to a hard parton together with its associated radiation, so such clustering is undesirable. This issue is resolved by modifying the distance measure, leading to the $k_\perp$ algorithm.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/JADE.jpeg}
    \caption{The JADE algorithm clustering soft gluons widely separated in angle, taken from Ref.~\cite{Banfi:2016yyq}.}
    \label{fig:JADE}
\end{figure}



\subsubsection{ The $k_\perp$ (Durham) algorithm}
Also known as the Durham algorithm~\cite{Catani:1991hj}, this approach follows the same procedure as JADE but employs a modified distance measure:
\begin{equation}
	 \label{eq:yij-De}
    	d^{\mathrm{Durham}}_{ij}=\frac{2(1-\cos\theta_{ij})}{Q^2}\min(E_i^2,E_j^2)\,.
\end{equation} 
At small angles, the numerator can be approximated to $\left[\min(E_i,E_j)\theta_{ij}\right]^2$, which corresponds to the squared relative transverse momentum of particle $i$ with respect to particle $j$ (for $E_i < E_j$). The use of the $\min$ function ensures that soft emissions, widely separated in angle, have a larger distance measure than those corresponding to a hard parton radiating a nearby soft gluon. This modification prevents unphysical clustering of unrelated soft particles and produces jets that more accurately reflect the underlying partonic structure.

\subsubsection{The Cambridge algorithm}
The Cambridge algorithm, first introduced in Ref.~\cite{Dokshitzer:1997in}, extends the Durham algorithm by employing angular ordering rather than transverse-momentum ordering. Unlike the previous two algorithms, it introduces an additional \emph{ordering variable}, $v_{ij}$, used alongside the distance measure $d^{\mathrm{Durham}}_{ij}$ from the Durham algorithm:
\begin{enumerate}
    \item \textbf{If only one particle remains,} stop the clustering and define this object as a jet.
    \item \textbf{Find the smallest $v_{ij}$} among all pairs of particles:
    \begin{equation}
        \label{eq:vij-cambridge}
        v_{ij} = 2(1 - \cos\theta_{ij})\,.
    \end{equation}
    \item \textbf{Identify the corresponding $d_{ij}$ value.} If $d_{ij} < d_{\mathrm{cut}}$, recombine the particles as in the Durham algorithm and return to step 1.
    \item \textbf{Otherwise,} remove the less energetic particle, label it as a jet, and return to step 1.
\end{enumerate}
This clustering procedure effectively reconstructs the sequence of gluon emissions in reverse, which typically occur at progressively smaller angles~\cite{Banfi:2016yyq}. As a result, the Cambridge algorithm is a better algorithm for the resolution of jet substructure and for reducing non- perturbative effects, which occur since emissions widely separated in angles are emitted independently from the hard legs. 

\subsection{Jet Algorithms for Deep-Inelastic Scattering}
\label{subsec: DIS-alg}
Deep inelastic scattering (DIS) is defined by the process
\begin{equation}
\label{eq:DIS-Process}
    e^-(k) + P \rightarrow e^-(k') + X\,,
\end{equation}
where $P^\mu$ is the momentum of the incoming proton and $X$ denotes the hadronic final state. The standard DIS invariants are
\begin{equation}
\label{eq:DIS-invariants}
    Q^2 = -q^2\,, \qquad
    \xB = \frac{Q^2}{2 P\!\cdot q}\,, \qquad
    \ydis = \frac{P\!\cdot q}{P\!\cdot k}\,,
\end{equation}
with $q^\mu = k^\mu - k'^\mu$ the momentum of the exchanged virtual photon. Here, $Q^2$ is the virtuality of the photon, $x$ is the Bjorken $x$ variable (fraction of momentum taken by the struck quark from the the incoming hadron), and $y$ is the energy transferred between leptonic and hadronic systems~\cite{Devenish:2004pb}. At leading order, the hadronic final state consists of a single outgoing parton,
\begin{equation}
\label{eq:DIS-LO}
    e^-(k) + p_{\mathrm{in}} \rightarrow e^-(k') + p_{\mathrm{out}}\,,
\end{equation}
where $p_{\mathrm{in}}^\mu$ and $p_{\mathrm{out}}^\mu$ are the momenta of the incoming and
outgoing partons, respectively.
The \emph{Breit frame} plays a central role in many DIS jet algorithms~\cite{Webber:1993bm}. It is defined such that the virtual photon carries no energy component,
\begin{equation}
\label{eq:DIS-photon}
    q^\mu = (0,0,0,-Q)\,,
\end{equation}
and is therefore purely space-like.  In this frame the proton momentum satisfies
$P^\mu = p_{\mathrm{in}}^\mu/x$, and the incoming and outgoing parton momenta take the simple form
\begin{equation}
\begin{aligned}
\label{eq:DIS-partons}
     p_{\mathrm{in}} ^\mu &= \frac{Q}{2}(1,0,0,+1)\,, \quad
    p_{\mathrm{out}}^{\mu} &= \frac{Q}{2}(1,0,0,-1)\,.
\end{aligned}
\end{equation}
Thus, in the Breit frame the proton and virtual photon collide head-on, as illustrated in Fig~\ref{fig:Breit-frame}. Within this frame, the proton remnant appears in the $\eta > 0$ region (the \emph{target hemisphere}), while the struck quark lies in the $\eta < 0$ region (the \emph{current hemisphere}). In practice, the jet clustering in this frame can lead to radiation from the proton remnant  being absorbed into the struck-quark jet, making the separation between the two hemispheres an important feature of DIS jet algorithms.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/Breit-frame.jpeg}
    \caption{Breit frame from Ref.~\cite{Arratia:2020ssx}}
    \label{fig:Breit-frame}
\end{figure}

\FloatBarrier
\noindent
The presence of an initial-state hadron requires a modification of the $e^+e^-$ jet algorithms described previously to account for the incoming beam. In sequential recombination algorithms, this can be achieved by introducing an additional quantity, the \emph{beam distance}, $d_{iB}$
\footnote{In hadron–hadron collisions, two beam distances are defined, $d_{iB}$ and $d_{i\bar{B}}$, corresponding to the two incoming beams.}. 

\subsubsection{$k_\perp$ DIS Algorithm}
As introduced in Ref.~\cite{Catani:1992zp}, the $k_\perp$ algorithm described in Section~\ref{subsec: e+e-} was extended to DIS. The procedure is defined in the Breit frame and is performed in two stages. The aim is to first cluster all particles into a \emph{beam jet} and  \emph{final-state macro-jets}, and then to resolve the jet sub-structure within the latter.
\begin{enumerate}
    \item \textbf{Pre-clustering into beam jet and macro-jets}
    \begin{enumerate}
        \item Define a hard-scattering scale, $E_t$, such that $Q^2\geq E_t^2 \gg \Lambda_{\mathrm{QCD}}^2$.
        \vspace{1em}
        
        \item For each particle $i$, compute the beam distance
        \begin{equation}
        	    \label{eq:kT-diB}
            d_{iB} = \frac{2 E_i^2 (1 - \cos\theta_{iB})}{E_t^2}\,,
        \end{equation}
        and for each pair $(i,j)$ compute the distance measure
        \begin{equation}
        	    \label{eq:kT-dij}
            d_{ij} = \frac{2 (1 - \cos\theta_{ij})}{E_t^2} \min(E_i^2, E_j^2)\,.
        \end{equation}        
        \item Identify the smallest value among all $\{d_{ij}, d_{iB}\}$:
        \begin{itemize}
            \item If the minimum is of type $d_{ij}$ and  $d_{ij} < 1$, merge $(p_i, p_j)$ into a pseudo-particle $p_{ij}$.
            \item If instead, it is of type $d_{iB}$ and $d_{iB} < 1$, assign $p_i$ to the beam jet.
        \end{itemize}
        
        \item Repeat the above steps for all particles and pseudo-particles until all
              remaining distances satisfy $d_{ij}, d_{iB} > 1$.
              The result is a beam jet and a set of final-state macro-jets. 
              \question{Assume the $d_{ij}, d_{iB} > 1$ get assigned to the beam jet.}
        \end{enumerate}
    \item \textbf{Resolving the macro-jets substructure}
    \begin{enumerate}
        \item Define a resolution parameter, $d_{\mathrm{cut}}=\frac{Q_0^2}{E_t^2}<1$.
        \item For each particle within the final-state macro-jet, evaluate the distance measures $d_{ij}$ and apply the same clustering procedure as the $k_\perp$ algorithm for $e^+e^-$ annihilation, described in Ref.~\cite{Catani:1991hj}.
    \end{enumerate}
\end{enumerate}


\subsubsection{Cambridge DIS Algorithm}
The Cambridge algorithm for deep-inelastic scattering, originally proposed in Ref.~\cite{Wobisch:1998wt}, is an extension of the $e^+e^-$ Cambridge algorithm, generalised in the same manner as the $k_\perp$ algorithm was extended from $e^+e^-$ collisions to DIS, in the section above. \\\\
The procedure follows the same steps as the $k_\perp$ DIS algorithm described above, but uses angular \emph{ordering variables}, $v_{ij}$ and $v_{iB}$, in place of the distance measures $d_{ij}$ and $d_{iB}$. The variable $v_{ij}$ is defined in Eq.~\ref{eq:vij-cambridge}, while the beam angular-ordering variable $v_{iB}$ is given by:
\begin{equation}
    v_{iB} = 2(1 - \cos\theta_{iB})\,.
\end{equation}
The clustering proceeds by finding the smallest value among $\{v_{ij}, v_{iB}\}$ and determining whether the corresponding object is associated with a final-state macro-jet or the beam jet. Once the pre-clustering is complete, the algorithm proceeds as in the $e^+e^-$ Cambridge algorithm to resolve the jet substructure within each macro-jet.

\noindent
\question{The reference used here (Ref.~\cite{Wobisch:1998wt}) is a bit awkward, since it both introduces the Aachen algorithm (for the first time) in DIS and proposes the Cambridge variant for DIS. Given that there is some confusion in the literature about the Cambridge versus Aachen algorithms, I am not sure whether it is worth getting into this distinction here. Would it be reasonable to avoid this discussion in this section and instead just note, in the earlier $k_\perp$ section, that the Cambridge variant for DIS was introduced in Ref.~\cite{Wobisch:1998wt}?} \\ \\
\question{Related to this, I am also unsure whether DIS should appear in this chapter at all. Since Chapter~3 will contain the DIS paper and will likely discuss~\cite{Catani:1992zp,Wobisch:1998wt} in the introduction, I am considering removing the DIS discussion from this chapter. In that case, would it make more sense to put the DIS $k_\perp$ algorithm in an appendix, or to include it briefly in the next section for completeness? See the beginning of Chapter~3 for how the paper is looking so far. Moreover, if I do remove this, I think it would be a good idea to discuss hadronic algorithms here?}








