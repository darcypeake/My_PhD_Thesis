\chapter{Quantum Chromodynamics}
\emph{Include: perturbation theory, UV/IR divergences, subtraction schemes (might need this for explaining the hard function in ARES)}
{\color{green} 
\begin{enumerate}
	\item QCD: quarks, gluons, matrices, Lagrangian, Feynman rules
	\begin{itemize}
	\item The running coupling: asymptotic freedom vs. confinement 
	\end{itemize}
	\item Perturbation theory (refer back to the Feynman rules)
	\begin{itemize}
	\item Divergences: UV and IR
	\item KLN theorem
	\end{itemize}
	\item High-energy physics
	\begin{itemize}
	\item Big picture of HEP + explanation
	\item Factorisation
	\item IRC Safety
	\end{itemize}
	\item Jet Physics
	\begin{itemize}
	\item Jet definition
	\item Types of algorithms
	\item Examples of algorithms
	\end{itemize}	
\end{enumerate}}

\section{QCD: The basics}
{\color{RoyalBlue}
In the 1940s, a number of unstable, strongly interacting particles—collectively known as hadrons—were discovered. In 1964, Gell-Mann~\cite{Gell-Mann:1964ewy} and Zweig~\cite{Zweig:1964ruk, Zweig:1964jf} proposed the quark model, which interpreted hadrons as composite states built from more fundamental spin-$\tfrac{1}{2}$ constituents called \emph{quarks}. The six known quarks are organised into three generations—light, intermediate, and heavy—as listed in Table~\ref{table:quark-properties}. In this picture, hadrons fall into two classes: mesons ($q\bar q$) and baryons ($qqq$).
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Light  & Intermediate & Heavy & Charge \\ \hline
$u$ (up)   & $c$ (charm)   & $t$ (top) & $+\tfrac{2}{3}$    \\ \hline
$d$   (down)	& $s$ (strange)    & $b$ (bottom)  & $-\tfrac{1}{3}$  \\ \hline
\end{tabular}
\caption{Properties of the 6 known quarks. More details on the mass can be found in~\cite{ParticleDataGroup:2024cfk}.}
\label{table:quark-properties}
\end{table}

Quantum Chromodynamics (QCD) is an $\mathrm{SU}(3)$ non-Abelian gauge theory that governs the strong interaction. It describes how quarks bind together to form hadrons, with the interaction mediated by the gauge bosons known as gluons. Quarks and gluons are collectively referred to as \emph{partons}, and they carry a conserved charge called colour. Quarks transform in the fundamental representation of $\mathrm{SU}(3)$, with fields denoted by $q_a$ for $a = 1,2,3$, corresponding to the three colour states typically labelled red, green, and blue. The associated antiquarks are written as $\bar{q}^a$. Gluons, denoted $\mathcal{A}^\mu_A$, transform in the adjoint representation of $\mathrm{SU}(3)$, where the index $A$ labels the eight colour degrees of freedom characteristic of the gauge group.\\ \\
The QCD Lagrangian density describes the dynamics of massless gluons and quarks of mass $m$:
\begin{equation}
\label{eq: L-QCD}
\mathcal{L}_{\mathrm{QCD}}
= \mathcal{L}_{\mathrm{classical}}
+ \mathcal{L}_{\mathrm{GF}}
+ \mathcal{L}_{\mathrm{ghost}}\,,
\end{equation}
where the classical part contains the kinetic terms for the gluon and quark fields, together with their interactions:
\begin{equation}
\label{eq: L-Classical}
\mathcal{L}_{\mathrm{classical}}
= -\frac{1}{4} F_{\mu\nu}^{A} F^{\mu\nu}_{A}
+ \sum_{f=1}^{n_f} \bar{q}^f_a (i\slashed{D} - m)_{ab}\, q^f_b \,.
\end{equation}
Here $n_f$ denotes the number of quark flavours, which takes the value $n_f = 6$ in the Standard Model (see Table~\ref{table:quark-properties}). The gluon dynamics are encoded in the non-Abelian field-strength tensor
\begin{equation}
F_{\alpha\beta}^{A}
= \partial_\alpha A_\beta^A
- \partial_\beta A_\alpha^A
- g_s f^{ABC} A_\alpha^B A_\beta^C \,,
\end{equation}
where the strength of the interaction is governed by the strong coupling $g_s$ which is commonly expressed in terms of the strong coupling constant, {\color{blue}(re-word this, done sloppily)}
\begin{equation}
    \alpha_s \equiv \frac{g_s^2}{4\pi}\,.
    \label{eq:coupling-constant}
\end{equation}
We use the Feynman slash notation $\slashed{D} = \gamma_\mu D^\mu$ for the covariant derivative,
\begin{equation}
(D_\mu)_{ab}
= \partial_\mu \delta_{ab}
+ ig_s (t^C A_\mu^C)_{ab}\,,
\end{equation}
where the gamma matrices satisfy the anti-commutation relation $\{\gamma^\mu,\gamma^\nu\} = 2 g^{\mu\nu}$. Throughout this work we adopt the metric convention $g^{\mu\nu} = (1,-1,-1,-1)$. The matrices $t^C$ denote the generators of the fundamental representation of $\mathrm{SU}(3)$. An explicit representation of these are given by the eight traceless and Hermitian Gell-Mann matrices, $\lambda^C$:
\begin{equation}
	t^C=\frac{1}{2}\lambda^C\,.
\end{equation}
These colour matrices satisfy the commutation relation
\begin{equation}
[t^A, t^B] = i f^{ABC} t^C\,,
\end{equation}
where $f^{ABC}$ are the structure constants of the $\mathrm{SU}(3)$ gauge group. \\ 
In addition to the commutation relation above, the generators obey the identities
\begin{equation}
\begin{aligned}
\mathrm{Tr}(t^A t^B) &= T_R\, \delta^{AB}, \qquad T_R = \frac{1}{2}, \\
\sum_A t^{A}_{ab} t^{A}_{bc} &= C_F\, \delta_{ac}, \qquad C_F = \frac{4}{3}, \\
\sum_{A,B} f^{ABC} f^{ABD} &= C_A\, \delta^{CD}, \qquad C_A = 3.
\end{aligned}
\end{equation}
\\The second term in Eq.~\ref{eq: L-QCD} is the gauge-fixing term:
\begin{equation}
    \mathcal{L}_{\mathrm{GF}}
    = -\frac{1}{2\xi} \left( \partial^\mu A_\mu^{A} \right)^{2}\,.
\end{equation}
This is required since the QCD Lagrangian is invariant under local $\mathrm{SU}(3)$ gauge transformations, which in turn introduces redundant degrees of freedom. This gauge fixing term removes this redundancy. The parameter $\xi$ specifies the choice of gauge; for example, $\xi = 1$ corresponds to Feynman gauge and $\xi = 0$ to Landau gauge.{\color{blue} (Double check that this is correct motivation.)}\\
The third term in Eq.~\ref{eq: L-QCD} is the ghost term,
\begin{equation}
\mathcal{L}_\mathrm{ghost} = \partial_\mu \eta^{A^\dagger}(D_{AB}^\mu\,\eta^B)\,,
\end{equation}
where $\eta^A$ are complex scalar fields known as Faddeev--Popov ghosts. These fields anti-commute and therefore obey Fermi statistics. Ghosts do not correspond to physical states; instead, they appear as a consequence of the gauge-fixing procedure in non-Abelian gauge theories.\\ \\
The Feynman rules extracted from the full QCD Lagrangian are shown in Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules}. {\color{blue} (Add: the propagators come from the kinetic terms, while the vertices come from the interaction terms and show how various particles couple to one another.)}
For brevity, the ghost Feynman rules are omitted, as they are not required for the calculations presented in this thesis. {\color{red} (Think about whether to say full or not as think it's actually only from the classical part.)}





\begin{figure}[h!]
\centering

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \diagram*{
        (a) -- [fermion, momentum={$p$}] (b),
    };
\end{feynman}
\node[left] at (a) {$a,i$};
\node[right] at (b) {$b,j$};
\node[right=1.0cm of b] {$=\; \delta^{ab}\dfrac{i}{(\slashed{p}-m+i\epsilon)_{ji}}$};
\end{tikzpicture}

\vspace{0.7cm}

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \diagram*{
        (a) -- [gluon, momentum={$p$}] (b),
    };
\end{feynman}
\node[left] at (a) {$A,\mu$};
\node[right] at (b) {$B,\nu$};
\node[right=1.0cm of b] {$=\; \delta^{AB}\dfrac{i}{p^{2}+i\epsilon}\!\left(-g_s^{\mu\nu}-(1-\xi)\dfrac{p^\mu\,p^\nu}{p^2+i\epsilon}\right)$};
\end{tikzpicture}

\caption{Feynman rules for the quark and gluon propagators.}
\label{fig:QCD-Propagator-Rules}
\end{figure}


\begin{figure}[h!]
\centering

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (a);
    \vertex[right=2cm of a] (b);
    \vertex[above right=1.2cm and 0.8cm of b] (c);
    \vertex[below right=1.2cm and 0.8cm of b] (d);
    \diagram*{
        (a) -- [gluon] (b),
        (b) -- [fermion] (c),
        (b) -- [anti fermion] (d),
    };
\end{feynman}
\node[left] at (a) {$A,\mu$};
\node[right] at (c) {$c,j$};
\node[right] at (d) {$b,i$};
\node[right=1.5cm of b] {$=\; -ig_s\,(t^A)_{cb}\,(\gamma^\alpha)_{ji}$};
\end{tikzpicture}

\vspace{0.7cm}

\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (v);
    \vertex[left=2cm of v] (a);
    \vertex[above right=1.3cm and 0.9cm of v] (b);
    \vertex[below right=1.3cm and 0.9cm of v] (c);

    \diagram*{
        (a) -- [gluon, momentum={$p$}] (v),
        (b) -- [gluon, momentum={$q$}] (v),
        (c) -- [gluon, momentum={$r$}] (v),
    };
\end{feynman}

\node[left] at (a) {$A,\mu$};
\node[above right] at (b) {$B,\nu$};
\node[below right] at (c) {$C,\gamma$};

\node[right=2.3cm of v] {
$\displaystyle
= -g_s\, f^{ABC}
\big[
(p-q)^\gamma g^{\mu\nu}
+ (q-r)^\mu g^{\nu\gamma}
+ (r-p)^\nu g^{\mu\gamma}
\big]
$
};

\end{tikzpicture}


\vspace{0.7cm}
\begin{tikzpicture}[baseline=(current bounding box.center)]
\begin{feynman}
    \vertex (v);
    \vertex[above left=of v]  (A) {$A,\mu$};
    \vertex[below left=of v]  (B) {$B,\nu$};
    \vertex[above right=of v] (C) {$C,\gamma$};
    \vertex[below right=of v] (D) {$D,\delta$};

    \diagram*{
        (v) -- [gluon] (A),
        (v) -- [gluon] (B),
        (v) -- [gluon] (C),
        (v) -- [gluon] (D),
    };
\end{feynman}

\node[right=3.1cm of v] {
$\displaystyle
\begin{aligned}
&= -ig_s^2  \left[f^{EAC}f^{EBD}(g^{\mu\nu}g^{\gamma\delta}-g^{\mu\delta}g^{\nu\gamma})\right.\\
&\qquad\quad + f^{EAD}f^{EBC}(g^{\mu\nu}g^{\gamma\delta}-g^{\mu\gamma}g^{\nu\delta})\\
&\qquad\quad \left.+ f^{EAB}f^{ECD}(g^{\mu\gamma}g^{\nu\delta}-g^{\mu\delta}g^{\nu\gamma})\right]
\end{aligned}
$
};
\end{tikzpicture}


\caption{Feynman rules for the quark--gluon vertex, the three--gluon vertex, and the four--gluon vertex.}
\label{fig:QCD-Vertex-Rules}
\end{figure}
}
{\color{orange}This section mainly used the pink book and lecture notes.}

\section{Perturbation Theory}
{\color{RoyalBlue}
With the QCD Lagrangian and corresponding Feynman rules established in the previous section, we can now outline how  calculations are performed in practice. Using the propagators and interaction vertices shown in Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules} respectively, we can construct Feynman diagrams. These diagrams offer a visual representation of the scattering (probability) amplitude $\mathcal{M}$ for a given process and by applying the Feynman rules we are able to calculate its value. \\ \\
From the structure of the interaction vertices, it is evident that either the emission of an additional gluon (a real correction) or the appearance of a loop (a virtual correction) within the Feynman diagram introduces extra powers of the strong coupling $\alpha_s$. This indicates that the scattering amplitude follows a perturbative expansion,
\begin{equation}
    \mathcal{M}
    = \mathcal{M}_0
    + \alpha_s\,\mathcal{M}_1
    + \alpha_s^2\,\mathcal{M}_2
    + \cdots\,,
    \label{eq:pQCD}
\end{equation}
where $\mathcal{M}_0$ is the tree-level (classical) contribution, often referred to as the leading-order (LO) or Born term, while the terms $\mathcal{M}_1$, $\mathcal{M}_2$, etc.\ represent higher-order (quantum) corrections to the Born and are often referred to as next-to-leading order (NLO), next-to-next-to-leading order (NNLO), and so on. 
{\color{red} (I am wondering whether it should be like, `the first non-zero term is LO/classical etc.')}\\ \\ 
Since $\alpha_s$ becomes small at high energies (as discussed in the next section), higher-order terms are increasingly suppressed in this regime. As a result, the perturbative series can be well approximated by its first few terms, yielding a \emph{fixed-order} (FO) prediction. This approach is known as perturbation theory, and its application to QCD is referred to as perturbative QCD (pQCD). Throughout this thesis, we will work within the framework of pQCD.
} \\ \\
{\color{orange} No reference for this section.}

\section{The running of the strong coupling $\alpha_s$}
{\color{RoyalBlue}
As noted in the previous section, pQCD relies on the strong coupling becoming small at high energies. This behaviour reflects the fact that $\alpha_s$ is not a fixed constant but instead \emph{runs} with the renormalisation scale $\mu_R$ -- an unphysical scale introduced by the renormalisation procedure, which will be discussed in the following section. The scale dependence of the coupling is governed by the renormalisation group equation
\begin{equation}
\label{eq:coupling-DE}
    \mu_R^2 \frac{\partial \alpha_s(\mu_R^2)}{\partial \mu_R^2} = \beta(\alpha_s)\,.
\end{equation}
The QCD $\beta$-function admits a perturbative expansion of the form
\begin{equation}
    \beta(\alpha_s) = -\!\left(\beta_0\,\alpha_s^2 + \beta_1\,\alpha_s^3 + \beta_2\,\alpha_s^4 + \cdots\right),
\end{equation}
with coefficients 
\begin{equation}
\begin{aligned}
    \beta_0 &= \frac{11 C_A - 4\,T_R\,n_f}{12\pi}\\[1em]
    \beta_1 &= \frac{17 C_A^2 - 5\,C_A\,n_f - 3\,C_F\,n_f}{2\pi\,(11 C_A - 2 n_f)}\\[1em]
    \beta_2 &= \frac{2857 C_A^3 + (54 C_F^2 - 615 C_F C_A - 1415 C_A^2)n_f + (66 C_F + 79 C_A)n_f^2}{288\pi^2\,(11 C_A - 2 n_f)}\,.
\end{aligned}
\end{equation}
It is worth noting that only $\beta_0$ and $\beta_1$ are renormalisation–scheme independent; the coefficients $\beta_2$ and higher depend on the choice of renormalisation scheme (here the $\overline{\mathrm{MS}}$ scheme, discussed later)\footnote{The concepts of renormalisation and renormalisation schemes will be introduced in the following section.}.
 {\color{red}(Am unsure if I need to have this bit about renormalisation scheme here. Also make sure we have the correct form of the $\beta$ functions.)}
Solving Eq.~\eqref{eq:coupling-DE} at leading order, using a reference scale $Q$, yields
\begin{equation}
\label{eq:scale-dependence}
    \alpha_s(\mu_R^2)
    = \frac{\alpha_s(Q^2)}
    {1 + \alpha_s(Q^2)\,\beta_0\,\ln\!\left(\tfrac{\mu_R^2}{Q^2}\right)}\, .
\end{equation}
From the sign of $\beta_0$ and the form equation~\ref{eq:scale-dependence}, the scale dependence of the strong coupling becomes apparent. As $\mu_R \to \infty$, the coupling decreases, and quarks and gluons behave increasingly like free particles. This behaviour is known as \emph{asymptotic freedom}, a regime in which pQCD provides an excellent approximation. Conversely, as $\mu_R \to 0$, the coupling grows large, signalling the breakdown of perturbation theory and the emergence of a strongly interacting regime in which quarks and gluons are confined into hadrons. This phenomenon is known as \emph{confinement}. \\\\The running of the coupling has also been confirmed experimentally, as illustrated in Fig.~\ref{fig:strong-coupling}. Throughout this thesis, we will assume that we are working in the high-energy regime, thereby exploiting asymptotic freedom. \\ \\
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/strong_coupling.pdf}
    \caption{Summary of determinations of $\alpha_s$ as a function of the energy scale $Q$, compared to the running of the coupling computed at five loops using the current PDG average $\alpha_s(m_Z^2) = 0.1180 \pm 0.0009$~\cite{ParticleDataGroup:2024cfk}. {\color{blue}(Need to change this.)}}
    \label{fig:strong-coupling}
\end{figure}
}
{\color{orange} This section used the pink and black book.}

\section{Divergences}
While perturbation theory is highly effective at high energies, it also introduces
certain problems in the form of divergences. These come in two forms:
\begin{itemize}
    \item \textbf{Ultraviolet (UV):} arise in loop diagrams when the momentum of the
    virtual particle becomes large.
    \item \textbf{Infrared (IR):} arise when gluon emissions are low energy (soft) or
    collinear (or anticollinear) to a high-energy (hard) parton.
\end{itemize}

\subsection*{UV Divergences}
Let us begin by discussing UV divergences. One Feynman rule not shown in
Figs.~\ref{fig:QCD-Propagator-Rules} and~\ref{fig:QCD-Vertex-Rules} is the rule associated
with loop diagrams. Each closed loop contributes an integration of the form
\begin{equation}
    \mathrm{loop} \;\longrightarrow\; \frac{d^D\ell}{(2\pi)^D}\,,
\end{equation}
where $\ell$ is the loop momentum. In other words, we must integrate over the momentum
carried by the virtual particle running inside the loop.
To understand how a UV divergence arises, consider the fermion bubble diagram shown in
Fig.~\ref{fig:fermion-bubble}.
\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=2]
\begin{feynman}
    \vertex (a) at (-2,0) {$\mu$, a};
    \vertex (b) at ( 2,0) {$\nu$, b};
    \vertex (c) at (-0.8,0);
    \vertex (d) at ( 0.8,0);

    \diagram*{
        (a) -- [gluon, momentum=$p$] (c),
        (d) -- [gluon, momentum=$p$] (b),
        (c) -- [fermion, half left, looseness=1.5, momentum=$p+q$] (d),
        (d) -- [fermion, half left, looseness=1.5, momentum=$q$] (c),
    };
\end{feynman}
\end{tikzpicture}
\caption{The fermion bubble.}
\label{fig:fermion-bubble}
\end{figure}
Taking the quarks to be massless (as we do throughout this thesis) and applying the Feynman rules, the diagram leads to an integral of the form
\begin{equation}
    I = \int d^4 q \, \frac{N^{\mu\nu}}{q^2 (p+q)^2}\,,
\end{equation}
where $N^{\mu\nu}$ denotes a numerator whose explicit form is not required for the present
discussion. For large loop momenta, the integral behaves as
\begin{equation}
    I \sim \lim_{\Lambda \to \infty} \int_0^\Lambda \frac{dq}{q}
      \sim \lim_{\Lambda \to \infty} \ln \Lambda\,,
\end{equation}
revealing a UV divergence.
We cannot allow divergences to remain in the theory, so we need a way to handle them. This is done through a procedure known as regularisation. Although several regularisation procedures  exist, in this thesis we use the one known as \emph{dimensional regularisation}.  This method
preserves both Lorentz and gauge invariance, and as we will see later can also be used
to handle infrared (IR) divergences. The idea behind dimensional regularisation is to promote the space-time dimension to $d = 4 - 2\varepsilon$ where $\varepsilon < 0$, so that, instead of logarithmic divergences, the integrals develop poles in $\varepsilon$. \\ \\
Once the poles have been isolated, the next step is to remove them. This is achieved by
redefining the parameters of the theory and introducing counterterms that cancel the
divergent pieces. This procedure is known as renormalisation. Throughout this thesis we
work in the $\overline{\mathrm{MS}}$ renormalisation scheme, in which the counterterms
subtract not only the $1/\varepsilon$ poles but also the accompanying constants
$\ln 4\pi$ and $\gamma_E$ (Euler–Mascheroni constant where $\gamma_E\approx0.5772$) that arise in dimensional regularisation. The renormalisation procedure introduces the renormalisation scale $\mu_R$, and the strong coupling $\alpha_s$ acquires a dependence on this scale, as discussed in the previous section.


\subsection*{IR Divergences}
In order to investigate these IRC divergences, let us consider the simplest QCD process: $e^+e^-$ annihilation to form hadrons ($e^+e^-\rightarrow \mathrm{hadrons}$), \cite{Luisoni:2015xha}. \\ \\
There is an important feature to note here. Due to quark-hadron duality~\cite{Shifman:2000jv}, we can say that every parton will go to a hadron \footnote{There are some exceptions}, and so we can approximate this process  of $e^+e^-\rightarrow \mathrm{hadrons}$ to $e^+e^-\rightarrow q\bar{q}$ as shown in Fig.~\ref{fig:photon-qq}. 
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}

            \vertex (e1) at (0,1) {\(e^-\)};
            \vertex (e2) at (0,-1) {\(e^+\)};

            \vertex at (1.5,0) (a);

           \vertex (b) at (3.5,0);

           \vertex (f1) at (4.8,1) {\(q\)};
            \vertex (f2) at (4.8,-1) {\(\overline{q}\)};
            \diagram* {
                (e1) -- [fermion] (a) -- [fermion] (e2),
                (a)  -- [photon, edge label=\(\gamma^*\)] (b),
                (b)  -- [fermion] (f1),
                (b)  -- [anti fermion] (f2),
            };

        \end{feynman}
    \end{tikzpicture}
    \caption{Feynman diagram of \(e^- e^+\) annihilation into a virtual \(\gamma^*/Z\) producing a \(q\bar{q}\) pair.}
    \label{fig:photon-qq}
\end{figure}
\newpage
We find that the leading-order this cross-section is
\begin{equation}
	\sigma_{\mathrm{LO}}=\frac{4\pi\alpha^2}{s}N_c\sum_fQ_f^2\,,
\end{equation}
where $Q_f$ is the electric charge of a given quark flavour where this equation is summed over all quark flavours and $N_c=3$ and $\alpha$ is the QED coupling constant. \\ \\
Now looking at the NLO cross-section, we find that there are three diagrams that constitute this: two from the real and one from the virtual, as shown in Figs.~\ref{fig:photon-qqg} and~\ref{fig:photon-qq(g)} respectively. 
\begin{figure}[h]
\centering
\begin{minipage}{0.45\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}

        \vertex (e1) at (0,1) {\(e^-\)};
        \vertex (e2) at (0,-1) {\(e^+\)};

        \vertex (a) at (1.5,0);

        \vertex (b) at (3.5,0);

        \vertex (f1) at (4.8,1) {\(q\)};
        \vertex (f2) at (4.8,-1) {\(\overline{q}\)};

        \vertex at ($(b)!0.5!(f1)$) (m1);

        \vertex at ($(m1)+(1.0,0)$) (g1) {\(g\)};

        \diagram*{
            (e1) -- [fermion] (a) -- [fermion] (e2),
            (a) -- [photon, edge label=\(\gamma^*\)] (b),

            (b) -- [fermion] (m1) -- [fermion] (f1),
            (b) -- [anti fermion] (f2),

            (m1) -- [gluon] (g1),
        };

    \end{feynman}
    \end{tikzpicture}

\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}

        \vertex (e1) at (0,1) {\(e^-\)};
        \vertex (e2) at (0,-1) {\(e^+\)};

        \vertex (a) at (1.5,0);

        \vertex (b) at (3.5,0);

        \vertex (f1) at (4.8,1) {\(q\)};
        \vertex (f2) at (4.8,-1) {\(\overline{q}\)};

        \vertex at ($(b)!0.5!(f2)$) (m2);

        \vertex at ($(m2)+(1.0,0)$) (g2) {\(g\)};

        \diagram*{
            (e1) -- [fermion] (a) -- [fermion] (e2),
            (a) -- [photon, edge label=\(\gamma^*\)] (b),

            (b) -- [fermion] (f1),
            (b) -- [anti fermion] (m2) -- [anti fermion] (f2),

            (m2) -- [gluon] (g2),
        };

    \end{feynman}
    \end{tikzpicture}

\end{minipage}
\caption{Two real-emission diagrams for \(e^- e^+ \to \gamma^* \to q\bar{q}g\): 
gluon emitted from the upper quark leg (left) and from the lower antiquark leg (right).}
\label{fig:photon-qqg}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}

            \vertex (e1) at (0,1) {\(e^-\)};
            \vertex (e2) at (0,-1) {\(e^+\)};

            \vertex [right=1.5cm of e1, yshift=-1cm] (a);

            \vertex [right=2.0cm of a] (b);

            \vertex [above right=2cm of b] (f1) {\(q\)};
            \vertex [below right=2cm of b] (f2) {\(\overline{q}\)};

            \vertex at ($(b)!0.5!(f1)$) (mid1);
            \vertex at ($(b)!0.5!(f2)$) (mid2);

            \diagram*{
                (e1) -- [fermion] (a) -- [fermion] (e2),

                (a) -- [photon, edge label=\(\gamma^*\)] (b),


                (b) -- [fermion] (f1),
                (b) -- [anti fermion] (f2),

                (mid1) -- [gluon] (mid2),
            };

        \end{feynman}
    \end{tikzpicture}

    \caption{NLO virtual diagram for \(e^-e^+ \!\rightarrow \gamma^* \!\rightarrow q\bar q\) with a virtual gluon exchanged between the quark and antiquark legs.}
    \label{fig:photon-qq(g)}
\end{figure}

We find that the cross-section for the real contributions in Fig.~\ref{fig:photon-qqg} is
\begin{equation}
\label{eq:qqg-real}
	\sigma^{q\bar{q}g}=\sigma_{\mathrm{LO}}\,\,C_F\,\frac{\alpha_s}{2\pi}\int_0^1dx_q\int_{1-x_q}^{1}dx_{\bar{q}}\,\,\frac{x_q^2+x_{\bar{q}}^2}{(1-x_q)(1-x_{\bar{q}})}\,,
\end{equation}
where $x_q=\tfrac{2E_q}{\sqrt{s}}$ and $x_{\bar{q}}=\tfrac{2E_{\bar{q}}}{\sqrt{s}}$ {\color{blue}(put in other formula for the $x_i$'s)}.
From here, we can see divergences occur when $x_{q,{\bar{q}}}\rightarrow 1$. Since
\begin{equation}
\begin{aligned}
1-x_q=\frac{x_{\bar{q}}\,E_g(1-\cos\theta_{{\bar{q}}g})}{\sqrt{s}}\,,\\
1-x_{\bar{q}}=\frac{x_{q}\,E_g(1-\cos\theta_{qg})}{\sqrt{s}}\,,
\end{aligned}
\end{equation}
we can see that singularities arise when there is:
\begin{enumerate}
	\item A soft emission i.e. $E_g\rightarrow 0$
	\item A collinear emission i.e. $\theta_{{\bar{q}}g},\theta_{qg}\rightarrow 0$
\end{enumerate}
Note soft divergence if: $x_q\rightarrow1$ \emph{and} $x_{\bar{q}}\rightarrow1$ while collinear divergence if: $x_q\rightarrow1$ \emph{or} $x_{\bar{q}}\rightarrow1$.
These are infrared and collinear divergences respectively, collectively termed IR divergences. 
As for UV divergences, to isolate these divergence we use dimensional regularisation, such that equation~\ref{eq:qqg-real} becomes
\begin{equation}
	\sigma^{q\bar{q}g}=\sigma_{\mathrm{LO}}\,\frac{\alpha_s}{2\pi}\frac{C_F}{\Gamma(1-\varepsilon)}\left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}\left(\frac{2}{\varepsilon^2}+\frac{3}{\varepsilon}-\pi^2+\frac{19}{2}+\mathcal{O}(\varepsilon)\right)\,,
\end{equation}
where terms proportional to $\frac{1}{\epsilon^2}$ come from the region where the gluon is soft and collinear, and terms proportional to $\frac{1}{\epsilon}$, which occur due to the gluon being only collinear to the quark (or antiquark).  \\ \\
We find that the contribution coming from the virtual diagram in Fig.~\ref{fig:photon-qq(g)} gives rise to poles with the opposite sign:
\begin{equation}
	\sigma^{q\bar{q}(g)}=\sigma_{\mathrm{LO}}\,\frac{\alpha_s}{2\pi}\frac{C_F}{\Gamma(1-\varepsilon)}\left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}\left(-\frac{2}{\varepsilon^2}-\frac{3}{\varepsilon}+\pi^2-8+\mathcal{O}(\varepsilon)\right)\,.
\end{equation}
By summing together the real and virtual diagram we obtain the NLO cross-section i.e. $\sigma_{\mathrm{NLO}}=\sigma^{q\bar{q}g}+\sigma^{q\bar{q}(g)}$
\begin{equation}
\sigma_{\mathrm{NLO}}=\sigma_{\mathrm{LO}}\,\frac{\alpha_s}{2\pi}\frac{C_F}{\Gamma(1-\varepsilon)}\left(\frac{4\pi\mu_R^2}{s}\right)^{\varepsilon}\left(\frac{3}{2}+\mathcal{O}(\varepsilon)\right)\,.
\end{equation}
This is finite and so by taking $\varepsilon\rightarrow0$, we obtain:
\begin{equation}
\sigma_{\mathrm{NLO}}=\frac{\alpha_s}{2\pi}\frac{3}{2}C_F\,\sigma_{\mathrm{LO}}\,.
\end{equation}
The fact that the real and virtual diagrams divergences cancel are in fact not a surprise and are a consequence of the KLN theorem. The KLN theorem states that this cancellation of IRC divergences between real emission and virtual diagrams occurs at every order in perturbation theory and for every process, provided we sum over all possible initial and final states. \\ \\
In this capacity, we find that the total cross-section is:
\begin{equation}
	\sigma = \sigma_{\mathrm{LO}}\left(1+\frac{\alpha_s}{2\pi}\frac{3}{2}C_F+\,\mathcal{O}(\alpha_s^2)\right)
\end{equation}
following the same form as the  perturbative expansion as the matrix elements in equation~\ref{eq:pQCD}\footnote{This makes sense as the cross-section is matrix element square.} \\ \\
{\color{orange} Done with Luisoni \& Marzani, Schwartz and the pink book \& thesis' and powerpoint. For UV divergences, no formal references right at this second.}

\section{Matrix element factorisation}
\subsection*{Soft factorisation}
\begin{equation}
|\mathcal{M}_{g, a_1\cdots(q,p_1,\cdots)}^{(0)}|^2\simeq-4\pi\alpha_s\sum_{ij}S_{ij}(q)\bra{\mathcal{M}_{a_1,\cdots}(p_1,\cdots)}\mathbf{T_i}\cdot\mathbf{T_j}\ket{\mathcal{M}_{a_1,\cdots}(p_1,\cdots)}\,,
\end{equation}
where $S_{ij}(q)=\frac{p_i\cdot p_j}{p_i\cdot q\,p_j\cdot q}$\,.

\subsection*{Collinear factorisation}
Sudakov parameterisation 
\begin{equation}
\begin{aligned}
	&p_1^\mu=zp^\mu+k_\perp^\mu-\frac{k_\perp^\mu}{z}\frac{n^\mu}{2p\cdot n}\,,\\
	&p_2^\mu=(1-z)p^\mu-k_\perp^\mu-\frac{k_\perp^\mu}{1-z}\frac{n^\mu}{2p\cdot n}\,.
\end{aligned}
\end{equation}

\begin{equation}
|\mathcal{M}_{a_1,a_2,\cdots(p_1,p_2,\cdots)}^{(0)}|^2\simeq4\pi\alpha_s\bra{\mathcal{M}_{a,\cdots}(p,\cdots)}\hat{\mathbf{P}}^{(0)}_{a_1\,a_2}(z,k_\perp;\epsilon)\ket{\mathcal{M}_{a,\cdots}(p,\cdots)}\,,
\end{equation}
where $\hat{\mathbf{P}}^{(0)}_{a_1\,a_2}(z,k_\perp;\epsilon)$ are the splitting functions which depends on the colours involved and have the following format
\begin{equation}
\begin{aligned}
	&\hat{\mathbf{P}}_{q\bar{q}}^{(0)}(z,k_\perp;\epsilon)=\hat{\mathbf{P}}_{\bar{q}q}^{(0)}(z,k_\perp;\epsilon)=\\
	&\hat{\mathbf{P}}_{qg}^{(0)}(z,k_\perp;\epsilon)=\hat{\mathbf{P}}_{{\bar{q}}g}^{(0)}(z,k_\perp;\epsilon)=\\
	&\hat{\mathbf{P}}_{gq}^{(0)}(z,k_\perp;\epsilon)=\hat{\mathbf{P}}_{g{\bar{q}}}^{(0)}(z,k_\perp;\epsilon)=\\
	&\hat{\mathbf{P}}_{gg}^{(0)}(z,k_\perp;\epsilon)=\,.
\end{aligned}
\end{equation}





\section{The Parton Model/ Factorisation}
High-energy hadronic collisions can be described by the QCD improved parton model. In this process, the hard scattering between two hadrons is the result of an interaction between quarks and gluons which are the constituents of the incoming hadrons. These partons take fractions of momenta of the parent hadron's momenta.  \\ \\
Because of this, we can take advantage of the factorisation formula
\begin{equation}
\label{eq:factorisation-formula}
	\sigma(P_1,P_2)=\sum_{i,j}\int_0^1dx_1\,dx_2\,f_i(x_1,\mu_F^2)\,f_j(x_2,\mu_F^2)\,\hat{\sigma}_{ij}(\alpha_s(\mu_R^2),\mu_R^2,\mu_F^2)+\mathcal{O}\left(\frac{\Lambda_{\mathrm{QCD}}^2}{Q^2}\right)\,,
\end{equation}
where $f_{i,j}$ are the parton distribution functions for parton $i$ and $j$ respectively which have momenta $p_1=x_1P_1$ and $p_2=x_2P_2$ where $x_1$ and $x_2$ are the momentum fractions. We are able to integrate over these momentum fractions, with the help of the parton distribution functions (PDFs) $f_i(x_1)$, which give the probability of finding a parton $i$ which has a momentum fraction $x_1$. We sum over all possible flavours of quark inside the proton, where how much the individual flavour contributes  to the total cross-section is determined by the parton-evel cross-section $\hat{\sigma}$ as well as by the PDF of that flavour quark. \\ \\
Equation~\ref{eq:factorisation-formula} is referred to as a factorisation formula since it can be \emph{factorised} into two parts: the PDF and the parton-level cross-section: the PDF and the parton-level cross-section. These quantities are very distinct: the parton-level cross-section accounts for the high-energy scattering of the process, and is calculable in pQCD, while the PDFs describe distribution of partons within the hadron. These are non-perturbative functions which are extracted from data and depend on the scale they are probed at. \\ \\
There is a scale not yet mentioned here, namely the factorisation scale $\mu_F$. This scale is an arbitary parameter and is thought of a scale which separates long and short distance physics where by considering a parton with transverse momenta $p_\perp$:
\begin{itemize}
	\item If $p_\perp<\mu_F$: it is considered to be part of the hadron structure and is absorbed into the PDF.
	\item If $p_\perp>\mu_F$: it is considered to be part of the partonic cross-section.
\end{itemize}
Finally, the term $\mathcal{O}\left(\frac{\Lambda_{\mathrm{QCD}}^2}{Q^2}\right)$ refers to the fact that this formula holds in the high-energy limit. \\ \\
{\color{orange}Used pink book, Edinburgh notes, and A Banfi powerpoint recommendation for this mainly.}
  



\section{IRC Safety} 
\label{sec: IRC}
The cross-section falls into a category of inclusive observables. For such observables, the soft and collinear divergences cancel completely between the real and virtual diagrams in the IR limit (where $E_g\ll E_q,E_{\bar{q}}$) \cite{Campbell:2017hsr}. Exclusive observables, on the other hand, contain singularities and therefore unphysical results. Therefore, in order to avoid the issue of infinities we must define these to be IRC safe observables, which ensure the divergences cancel \cite{Luisoni:2015xha}, \cite{McAslan:2017bqp}, \cite{Arpino:2020smn}. \\ \\
An IRC safe observable is one that does not change regardless of the number of soft or collinear emissions, such that it obeys the following:
\begin{equation}
V(\{q\},k_1,\cdots ,k_n)=V(\{q\},k_1,\cdots , k_{j+1},\cdots ,k_n),\quad \text{when}\quad E_{j+1}\rightarrow0\quad\text{or}\quad\vec{k}_{j+1}\parallel \vec{q}_{\text{emit}}
	\label{eq:IRC-safety}
\end{equation}
where $V$ is the observable in question, $\{q\}$ are the hard partons, $k_{j+1}$ is the additional emission and ${q}_{\text{emit}}$ is the parent parton which emits the additional gluon. While equation~\eqref{eq:IRC-safety} holds for a single emission, the above must be true for any number of emissions. Therefore, IRC safe observables can be calculated to all orders in perturbation theory.










\section{High-energy physics}
\subsection*{Explanation of a high-energy collision}
Give explanation at the beginning. 
\emph{Include: factorisation at high-energy limit, what a jet is, the process following a high-energy collision, IRC Safety, resummation requirement.}
{\color{green} Add in the big picture thing that is used in every single thesis here I think.}



\section{Jet Physics}
{\color{RoyalBlue}
Jets are among the most frequently observed objects in proton–proton collisions at the LHC. They appear as highly collimated sprays of hadrons resulting from the hadronisation of energetic quarks and gluons produced in high-energy processes~\cite{Banfi:2016yyq}. When a hard parton is created in a short-distance interaction, it radiates gluons in a similarly collimated pattern along its initial direction. These gluons can in turn branch into further gluons or quark–antiquark pairs~\cite{Schwartz:2014sze}. As the radiation proceeds, the typical energy scale of the process decreases and the interactions between the partons become stronger, until they reach an energy of order $\Lambda_{\mathrm{QCD}}$. At this stage, the partons cluster together to form the final-state hadrons observed in the detector. These hadrons tend to group into fairly energetic, collimated clumps - known as \emph{jets}~\cite{Schwartz:2014sze, Campbell:2017hsr, Banfi:2016yyq}.
}




\subsection{Jet Definition}
{\color{RoyalBlue}
As described above, jets are complex, messy, and inherently ambiguous objects. To be able to describe them in a well-defined and reproducible way, we must introduce a \emph{jet definition}, which consists of the following components~\cite{Salam:2010nqg}:
\begin{enumerate}
\item a \emph{jet algorithm}: a systematic procedure for grouping final-state particles into jets and determining the number of jets present in an event, i.e.\ a set of rules that cluster particles into a given jet;
\item the algorithm's \emph{parameters}: these specify the proximity required between two particles for them to be recombined into a single entity belonging to the same jet;
\item a \emph{recombination scheme}: this defines how the momenta of two particles are combined to form the momentum of the new clustered particle — the most commonly used being the $E$-scheme, , which is a four-momentum sum, i.e.\ $p_i^\mu + p_j^\mu = p_k^\mu$.
\end{enumerate}
In the next subsection, we discuss the jet algorithm and its input parameters in more detail. }

\subsection{Jet Algorithm}
{\color{RoyalBlue}
In 1990, there was significant discussion within the high-energy physics community about how jets should be properly defined. To address this, a group of physicists formulated a set of requirements that a well-defined jet algorithm should satisfy, outlined in a document known as the \emph{Snowmass Accord}~\cite{Huth:1990mi}. The criteria are as follows:
\begin{enumerate}
    \item Simple to implement in an experimental analysis;
    \item Simple to implement in a theoretical calculation;
    \item Defined at any order in perturbation theory;
    \item Yields a finite cross section at any order in perturbation theory;
    \item Yields a cross section that is relatively insensitive to hadronisation effects.
\end{enumerate}
IRC safety ensures that jets defined at the detector, hadron, and parton levels are essentially equivalent, thereby satisfying the final three requirements outlined above. For IRC-safe observables, the effects of hadronisation are suppressed by inverse powers of the energy scale used in the process. Consequently, at higher energies, the correspondence between hadronic and partonic observables becomes increasingly accurate~\cite{Banfi:2016yyq}.
Overall, these requirements allow us to to regard jets as well-defined objects whose properties can be either determined by their constituent hadrons or underlying partons. This enables direct comparison between experimental measurements and theoretical calculations at the parton level. \\ \\
A wide variety of jet algorithms exist, each with its own advantages and limitations. The choice of algorithm depends on the specific physics question being addressed and the type of information one seeks to extract from an event. In general, jet algorithms can be divided into two broad classes: \emph{sequential recombination algorithms} and \emph{cone algorithms}~\cite{Banfi:2016yyq},~\cite{Salam:2010nqg}.
\begin{itemize}
    \item \textbf{Cone algorithms:} These group particles within a fixed radius $R$ in $(\eta,\phi)$ space, such that the particles whose transverse energy deposits fall inside the circular region are clustered into a jet. In three dimensions, these regions appear as cones. Different implementations vary in how they search for and define these cones. Cone algorithms are often described as \emph{top-down} algorithms.

    \item \textbf{Sequential recombination algorithms:} These iteratively cluster the closest particles according to a chosen distance measure until a stopping criterion is reached. Variations arise from different definitions of the distance measure (e.g.\ relative transverse momentum or angular separation between particles) and from the choice of stopping condition. Sequential recombination algorithms are often referred to as \emph{bottom-up} algorithms.
\end{itemize}
In this thesis, we focus exclusively on sequential recombination algorithms. The following sections discuss several of these algorithms to provide background for the new DIS algorithm introduced in Chapter~\ref{chapter: DIS}. For a comprehensive review of jets and jet algorithms across different processes, see Ref.~\cite{Salam:2010nqg}.
}

\subsection{Jet Algorithms for $e^+e^-$ Collisions}
\label{subsec: e+e-}
{\color{RoyalBlue}
Jet algorithms for electron–positron collisions follow a common iterative clustering procedure. Each pair of particles is assigned a \emph{distance measure}, $d_{ij}$, which determines how closely they are related. The closest pair is iteratively recombined until all remaining objects are separated by more than the chosen \emph{resolution parameter}, $d_{\mathrm{cut}}$.
This framework forms the basis of the JADE and Durham algorithms, while the Cambridge algorithm extends it by introducing an additional \emph{ordering variable}, $v_{ij}$, as discussed in the following sections.

\subsubsection{The JADE algorithm}
The first sequential recombination algorithm was introduced by the JADE Collaboration in 1988~\cite{JADE:1988xlj} and is defined as follows:
\begin{enumerate}
    \item \textbf{Define a resolution parameter} $d_{\mathrm{cut}}$.
    \item \textbf{Compute the distance measure} for every pair of particles $i$ and $j$:
    \begin{equation}
        \label{eq:yij-jade}
        d^{\mathrm{JADE}}_{ij} = \frac{2E_iE_j(1 - \cos\theta_{ij})}{Q^2}\,,
    \end{equation}
    where $Q$ is the total centre-of-mass energy, $E_i$ is the energy of particle $i$, and $\theta_{ij}$ is the angle between particles $i$ and $j$.
    \item \textbf{Identify the smallest $d_{ij}$ value.} If this minimum satisfies $d_{ij} < d_{\mathrm{cut}}$, the two particles are recombined into a pseudo-particle according to the chosen recombination scheme.
    \item \textbf{Repeat the procedure} from step 2 until all remaining pairs satisfy $d_{ij} > d_{\mathrm{cut}}$. The remaining objects are then defined as jets.
\end{enumerate}
A drawback of the JADE algorithm is its tendency to cluster soft pairs of gluons that are widely separated in angle. This can lead to situations where a hard parton is incorrectly merged with a soft gluon that was not emitted from it. Physically speaking, a jet should constitute to a hard parton together with its associated radiation, so such clustering is undesirable. This issue is resolved by modifying the distance measure, leading to the $k_\perp$ algorithm.
}


\subsubsection{ The $k_\perp$ (Durham) algorithm}
{\color{RoyalBlue}
Also known as the Durham algorithm~\cite{Catani:1991hj}, this approach follows the same procedure as JADE but employs a modified distance measure:
\begin{equation}
	 \label{eq:yij-De}
    	d^{\mathrm{Durham}}_{ij}=\frac{2(1-\cos\theta_{ij})}{Q^2}\min(E_i^2,E_j^2)\,.
\end{equation} 
At small angles, the numerator can be approximated to $(\min(E_i,E_j)\theta_{ij})^2$, which corresponds to the squared relative transverse momentum of particle $i$ with respect to particle $j$ (for $E_i < E_j$). The use of the $\min$ function ensures that soft emissions, widely separated in angle, have a larger distance measure than those corresponding to a hard parton radiating a nearby soft gluon. This modification prevents unphysical clustering of unrelated soft particles and produces jets that more accurately reflect the underlying partonic structure.
}
\subsubsection{The Cambridge algorithm}
{\color{RoyalBlue}
The Cambridge algorithm, first introduced in Ref.~\cite{Dokshitzer:1997in}, extends the Durham algorithm by employing angular ordering rather than transverse-momentum ordering. Unlike the previous two algorithms, it introduces an additional \emph{ordering variable}, $v_{ij}$, used alongside the distance measure $d^{\mathrm{Durham}}_{ij}$ from the Durham algorithm:
\begin{enumerate}
    \item \textbf{If only one particle remains,} stop the clustering and define this object as a jet.
    \item \textbf{Find the smallest $v_{ij}$} among all pairs of particles:
    \begin{equation}
        \label{eq:vij-cambridge}
        v_{ij} = 2(1 - \cos\theta_{ij})\,.
    \end{equation}
    \item \textbf{Identify the corresponding $d_{ij}$ value.} If $d_{ij} < d_{\mathrm{cut}}$, recombine the particles as in the Durham algorithm and return to step 1.
    \item \textbf{Otherwise,} remove the less energetic particle, label it as a jet, and return to step 1.
\end{enumerate}
This clustering procedure effectively reconstructs the sequence of gluon emissions in reverse, which typically occur at progressively smaller angles~\cite{Banfi:2016yyq}. As a result, the Cambridge algorithm is a better algorithm for the resolution of jet substructure and for reducing non- perturbative effects, which occur since emissions widely separated in angles are emitted independently from the hard legs. 
}
{\color{red} (Not understanding why this will give rise to better substructure and reduced NP effects.) }

\subsection{Jet Algorithms for Deep-Inelastic Scattering}
\label{subsec: DIS-alg}
{\color{RoyalBlue}
 Deep-inelastic scattering (DIS) is the process:
\begin{equation}
\label{eq: DIS}
    e^-(k) + N(P) \rightarrow e^-(k') + X(p_X)\,,
\end{equation}
where $N$ denotes the incoming hadron (usually a proton) and $X$ represents all final-state hadrons produced. In DIS processes, three lorentz invariants are often used to describe the kinematics:
\begin{equation}
\begin{aligned}
Q^2=-q^2\,, \qquad x=\frac{Q^2}{2P\cdot q}\,, \qquad y=\frac{P\cdot q}{P\cdot k}\,,
\end{aligned}
\end{equation}
where $Q^2$ is the virtuality of the photon, $x$ is the Bjorken $x$ variable (fraction of momentum taken by the struck quark from the the incoming hadron), and $y$ is the energy transferred between leptonic and hadronic systems~\cite{Devenish:2004pb}.  {\color{blue}(Need to get some more information on invariants (particularly $y$.)}
 \\ \\
At LO, the process produces a single outgoing parton in its final hadronic state:
\begin{equation}
    e^-(k) + N(P) \rightarrow e^-(k') + p_{\mathrm{out}}(p')\,.
\end{equation}
DIS processes are often analysed in the \emph{Breit frame}, defined as the reference frame in which the exchanged virtual photon carries no energy component, with four-momentum $q^{\mu} = (0, 0, 0, -Q)$. In this frame $P^{\mu} = p^{\mu}/x$, where  $ p^{\mu}$ is the momentum of the incoming parton, $p_{\mathrm{in}}$. In the Breit frame, the momenta of the incoming and outgoing partons are:  
\begin{equation}
\begin{aligned}
    p^{\mu} &= \frac{Q}{2}(1, 0, 0, +1)\,, \qquad
    p'^{\mu} = \frac{Q}{2}(1, 0, 0, -1)\,.
\end{aligned}
\end{equation}
In this frame, the proton and the virtual photon collide head-on, providing a clear separation between the incoming proton and the struck quark.\\ \\
 The presence of an initial-state hadron requires a modification of the $e^+e^-$ jet algorithms described previously to account for the incoming beam. In sequential recombination algorithms, this can be achieved by introducing an additional quantity, the \emph{beam distance}, $d_{iB}$~\cite{Salam:2010nqg}
\footnote{In hadron–hadron collisions, two beam distances are defined, $d_{iB}$ and $d_{i\bar{B}}$, corresponding to the two incoming beams.}.} \\ \\
{\color{blue} (I think we need some information on the variables i.e. $x$, $y$, and $Q^2$, along with a few images of the lab frame DIS and the Breit frame DIS, and also some information on TFR and CFR.)}


\subsubsection{$k_\perp$ DIS Algorithm}
{\color{RoyalBlue}
As introduced in Ref.~\cite{Catani:1992zp}, the $k_\perp$ algorithm described in Section~\ref{subsec: e+e-} was extended to DIS. The procedure is defined in the Breit frame and is performed in two stages. The aim is to first cluster all particles into a \emph{beam jet} and  \emph{final-state macro-jets}, and then to resolve the jet sub-structure within the latter.
\begin{enumerate}
    \item \textbf{Pre-clustering into beam jet and macro-jets}
    \begin{enumerate}
        \item Define a hard-scattering scale, $E_t$, such that $E_t^2 \gg \Lambda_{\mathrm{QCD}}^2$.
        \item For each particle $i$, compute the beam distance:
        \begin{equation}
        \label{eq:DIS-durham-diB}
            d_{iB} = \frac{2E_i^2(1 - \cos\theta_{iB})}{E_t^2}\,,
        \end{equation}
        where $\theta_{iB}$ is the angle between particle $i$ and the beam (initial-state proton) direction.

        \item Compute the distance measure for every pair of particles $i$ and $j$:
        \begin{equation}
        \label{eq:DIS-durham-dij}
            d_{ij} = \frac{2(1 - \cos\theta_{ij})}{E_t^2}\min(E_i^2, E_j^2)\,.
        \end{equation}

        \item Identify the smallest value among $\{d_{ij}, d_{iB}\}$:
        \begin{itemize}
            \item If $d_{ij} < 1$ and is the smallest, combine $(p_i, p_j)$ into a pseudo-particle $p_{ij}$, using the $E$-scheme recombination scheme.
            \item If $d_{iB} < 1$ and is the smallest, assign $p_i$ to the beam jet.
        \end{itemize}
        \item Repeat the procedure iteratively from step~(b) for all particles and pseudo-particles not yet assigned to the beam jet, until all remaining objects satisfy $d_{ij}, d_{iB} > 1$. The result is a final set of clustered objects consisting of a beam jet and final-state macro-jets. {\color{red}(I am unsure what happens to the particles which are greater than 1. I think they are just macrojets. I am also unsure if there is 1 or multiple macrojets)}
    \end{enumerate}

    \item \textbf{Resolving the jet structure of the macro-jet}
    \begin{enumerate}
        \item Define a resolution parameter, $d_{\mathrm{cut}}$.
        \item For each particle within the final-state macro-jet, evaluate the distance measures $d_{ij}$ and apply the same clustering procedure as the $k_\perp$ algorithm for $e^+e^-$ annihilation, described in Section~\ref{subsec: e+e-} to the final-state macrojet.
    \end{enumerate}
\end{enumerate}
}


\subsubsection{Cambridge DIS Algorithm}
{\color{RoyalBlue}
The {\color{blue}(exclusive)} Cambridge algorithm for deep-inelastic scattering, originally proposed in Ref.~\cite{Wobisch:1998wt}, is an extension of the $e^+e^-$ Cambridge algorithm introduced in Section~\ref{subsec: e+e-}, generalised in the same manner as the $k_\perp$ algorithm was extended from $e^+e^-$ collisions to DIS, in the section above. \\\\
The procedure follows the same steps as the $k_\perp$ DIS algorithm described above, but uses angular \emph{ordering variables}, $v_{ij}$ and $v_{iB}$, in place of the distance measures $d_{ij}$ and $d_{iB}$. The variable $v_{ij}$ is defined in Eq.~\ref{eq:vij-cambridge}, while the beam angular-ordering variable $v_{iB}$ is given by:
\begin{equation}
    v_{iB} = 2(1 - \cos\theta_{iB})\,.
\end{equation}
The clustering proceeds by finding the smallest value among $\{v_{ij}, v_{iB}\}$ and determining whether the corresponding object is associated with a final-state macro-jet or the beam jet. Once the pre-clustering is complete, the algorithm proceeds as in the $e^+e^-$ Cambridge algorithm (see Section~\ref{subsec: e+e-}) to resolve the jet substructure within each macro-jet.
}
{\color{blue} (Add in: widely separated in angle are attached to the hard leg i.e. no multiple gluon clustering - soft jet freezing.)}







