\chapter{Quantum Chromodynamics}
\emph{Include: perturbation theory, UV/IR divergences, subtraction schemes (might need this for explaining the hard function in ARES)}
{\color{green} Need to add QCD Lagrangian and how Feynman rules are founded I think first. Also need reference to the Standard Model but explain we work purely in QCD. We may need to have Higgs mechanism since we are doing Higgs plus one jet.}
\section{QCD: The basics}
Quantum chromodynamics (QCD) is an $SU(3)$ non-Abelian gauge theory describing the strong interaction between quarks and gluons - collectively referred to as partons. Quarks are Dirac spinors that transform under the fundamental representation of the gauge group $SU(3)$, while gluons are spin-1 vector gauge bosons transforming under the adjoint representation. Acting as mediators of the strong force, gluons facilitate interactions among quarks. Partons possess a type of charge known as colour: quarks exhibit three colours - red, green, and blue - whereas gluons have eight colour states. Quarks combine to form bound states called hadrons, which include mesons ($q\bar{q}$) with integer spin and baryons ($qqq$) with half-integer spin. \\ \\
In QCD, the interaction vertices can be derived from the QCD Lagrangian. The corresponding Feynman rules for quark-gluon and gluon self-interactions are depicted in figures \ref{fig:qgg}, \ref{fig:3-gluon}, and \ref{fig:gggg}. These vertices are essential for computing the scattering amplitudes of a given process, which in turn allows us to determine the cross-section which describes the probability of a given event. 



\begin{figure} [h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}
            \vertex (a);
            \vertex[right=2cm of a] (b);
            \vertex[above right=1.5cm and 1cm of b] (c);
            \vertex[below right=1.5cm and 1cm of b] (d);
            
            \diagram* {
                (a) -- [gluon] (b),
                (b) -- [fermion] (c),
                (b) -- [anti fermion] (d),
            };
        \end{feynman}
        \node[left] at (a) {$\mu,a$};

        \node[right=1.5cm of b] { $=-ig_s\gamma^\mu\,t_R^a$ };
        
    \end{tikzpicture}
        \caption{The three-point gluon-quark vertex.}
        \label{fig:qgg}
\end{figure}
%Second Feynman diagram.
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}
            \vertex (a);
            \vertex[right=2cm of a] (b);
            \vertex[above right=1.5cm and 1cm of b] (c);
            \vertex[below right=1.5cm and 1cm of b] (d);
            
            \diagram* {
                (a) -- [gluon, momentum={$p_1$}] (b),
                (b) -- [gluon, momentum={$p_2$}] (c),
                (b) -- [gluon, momentum={$p_3$}] (d),
            };
        \end{feynman}
        \node[left] at (a) {$\alpha, a$};
        \node[above right] at (c) {$\beta, b$};
        \node[below right] at (d) {$\gamma, c$};
        \node[right=1.5cm of b] { $= -g_sf^{abc}\left[(p_1+p_2)_{\gamma}\,\eta_{\alpha\beta}+(p_3-p_2)_{\alpha}\,\eta_{\beta\gamma}-(p_1+p_3)_{\beta}\,\eta_{\alpha\gamma}\right]$ };
    \end{tikzpicture}
    \caption{The three-point gluon vertex}
    \label{fig:3-gluon}
\end{figure}
%Sort the arrows, momenta and captioning out. 
%Third Feynman diagram. 
\begin{figure} [h]
\centering
\begin{tikzpicture}
  \begin{feynman}
    \vertex (v) at (0,0);
    \vertex [above left=of v] (a) {\(\alpha, a\)};
    \vertex [below left=of v] (b) {\(\beta, b\)};
    \vertex [above right=of v] (c) {\(\gamma, c\)};
    \vertex [below right=of v] (d) {\(\delta, d\)};
    
    \diagram* {
      (v) -- [gluon] (a),
      (v) -- [gluon] (b),
      (v) -- [gluon] (c),
      (v) -- [gluon] (d),
    };
  \end{feynman}
  \node[right=3cm of v] (eq) {
    \( = \quad \text{$-ig_s^2\left[f^{abe}f^{cde}(\eta_{\alpha\gamma}\eta_{\beta\delta}-\eta_{\alpha\delta}\eta_{\beta\gamma})+{\text{cyclic\,permutations\,of}} \,(a, b, c, d)\right]$} \)
  };
\end{tikzpicture}
\caption{The four-point gluon vertex.}
\label{fig:gggg}
\end{figure}
In these figures, the $3\times3$ matrix in colour space, $t_R^a$, represents the colour factor, while the structure constants $f^{abc}$  belong to the gauge group $SU(3)$. The parameter $g_s$ is related to the strong coupling of QCD $\alpha_s$ by the following: {\color{blue}Check this equation.} 
\begin{equation}
	\alpha_s(Q)=\frac{g_s^2(Q)}{4\pi}\,,
	\label{eq:coupling-constant}
\end{equation}
where the $Q$ is merely describing the dependence on energy scale. 
{\color{blue}Unsure whether to put $Q^2$ in the brackets}
Due to the nature of QCD, $\alpha_s$ increases as  $Q$ decreases. {\color{blue} Add more about this - 'due to the nature is a bit vague - explain why.} In the regions of low energy, where $\alpha_s$ becomes large, quark confinement occurs. This is the phenomenon that quarks cannot exist in isolation and instead they are bound together with gluons to form hadrons.  {\color{blue} Bound together with gluons?} This region is the non-perturbative regime and is where perturbation theory is no longer applicable. \\ \\
Conversely, at high energies where $Q$ is large and $\alpha_s$ is small, QCD exhibits asymptotic freedom. In this regime, quarks and gluons behave as free particles and where perturbation theory occurs (again explained later) provides us with a good approximation. This behaviour is illustrated in figure~\ref{fig:alpha_s_plot}, which shows the running of $\alpha_s$ with energy scale.  {\color{blue}Generate a better graph.} Throughout this thesis, we may assume to always be working in the high-energy limit, exploiting the property of asymptotic freedom.
{\color{blue}Rewrite this.} 
{\color{green}Add plot.}

\subsection{Perturbation Theory}
As discussed in the previous section, perturbative QCD (pQCD) can be used in the high-energy limit. We will now discuss the details of pQCD. Looking at the vertices in figures \ref{fig:qgg} and \ref{fig:3-gluon} {\color{blue}(what about the other figure - surely this gives two emissions (fact check this))}, we see that every gluon emission gives rise to one power of $g_s$. The cross-section can therefore be expressed as a power series in $\alpha_s$:
\begin{equation}
	\sigma=c_0+c_1\cdot\alpha_s+c_2\cdot\alpha_s^2+\cdots\,,
	\label{eq:pQCD}
\end{equation}
where $c_i$ are constant terms {\color{blue}( Known as what?).} 
Since $\alpha_s$ is small in the high-energy limit {\color{blue}(Better way to say this)}, the higher order terms in this expansion are expected to become become increasingly small. This allows a good approximation for the full result to come from the first couple of terms of the expansion -  this notion is referred to as perturbation theory {\color{blue}(Better way to say this)}. Calculating the terms in this truncated expansion is referred to as a fixed-order (FO) calculation, where the terms with the lowest power of $\alpha_s$ along with a non-zero coefficient $c_i$ is known as leading-order (LO). The next contribution, with the next smallest powers $\alpha_s$ is termed next-to-leading-order (NLO) and so on (NNLO etc.) {\color{blue}(A briefer way to say this hopefully).} Jet physics is an exclusively high-energy process and therefore pQCD can be used \cite{Schwartz:2014sze}, \cite{Campbell:2017hsr}. {\color{blue}(This ending kind of comes out of nowhere and I think it needs to be better linked).} 

\section{Infrared Divergences}
{\color{blue} Need to reword this whole section - start back from here.} \\ \\ 
While perturbation theory is a fantastic tool used in the high-energy limit - it does come with problems in the form of divergences{\color{blue} (are these divergences problems?)}. There are two types of divergences, the first referred to as ultraviolet (UV) divergences. This occurs when considering a loop diagram such that we integrate over the momentum of a virtual particle {\color{blue} (maybe a little more information on this and fact check)}. The other type that occur are known as infrared and collinear (IRC) divergences {\color{blue} (can we just call them IR divergences?)}. {\color{blue} (Better way to write this).} In order to investigate these IRC divergences, let us consider the simplest QCD process: the production of a quark-antiquark pair from either a virtual photon or a $Z$-boson ($e^+e^-\rightarrow q\bar{q}$) \cite{Luisoni:2015xha}, \cite{McAslan:2017bqp}, \cite{Arpino:2020smn}. In this example, we choose to look at the case of the photon where the LO diagram is shown in figure \ref{fig:photon-qq}. 
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}
            \vertex (a) {\(\gamma\)};
            \vertex [right=of a] (b);
            \vertex [above right=of b] (f1) {\(q\)};
            \vertex [below right=of b] (f2) {\(\overline{q}\)};
            
            \diagram* {
                (a) -- [photon] (b) -- [fermion] (f1),
                           (b) -- [anti fermion] (f2),
            };
        \end{feynman}
    \end{tikzpicture}
    \caption{Feynman diagram showing the production of $q\bar{q}$ from a photon (LO process).}
    \label{fig:photon-qq}
\end{figure}
The NLO diagram process can be shown in figures \ref{fig:photon-qg} and \ref{fig:photon-bar-qg} and depicts the process where an additional gluon is radiated from either  $q$ or $\bar{q}$ ($e^+e^-\rightarrow q\bar{q}g$). 
{\color{green} Add figures.}


We wish to consider the NLO cross-section, which we will not calculate but simply state the result:
 \begin{equation}
	\sigma_{\gamma\rightarrow q\bar{q}g}=\int[d\Phi_{3}]\,|M_{\gamma\rightarrow q\bar{q}g}|^2=C_F\,g_s^2\int[d\Phi_{2}]\,|M_{q\bar{q}}|^2\,\frac{d^3\vec{k}}{(2\pi)^32E_g}\Theta(E_g)\frac{2p_1p_2}{(p_1k)(p_2k)}\,,
	\label{eq:qqg-cross-section}
\end{equation}
where $E_q$, $E_{\bar{q}},$ and $E_g$ are the energies of the quark, anti-quark and gluon respectively. In the first step, we integrate with respect to the three-body phase space $d\Phi_{3}$, since there are three-particles present in the final state. The second equality holds only if we assume $E_g\ll E_q,E_{\bar{q}}$ \emph{18/09/24 i.e. in the limit where the gluon is soft such that it factorises into a LO matrix element squared and a real gluon emission}. In this case we see that the total cross-section can be factorised into a $q\bar{q}$ piece and a gluon piece. The $q\bar{q}$ piece is the cross-section at leading order, $\int[d\Phi_{2}]\,|M_{q\bar{q}}|^2$, whereas the gluon piece is the following:%Check this is all true - is this the idea that it can only happen when the gluon is soft? Is it worthwhile mentioning the hard process of e+e-->qbar{q}?
\begin{equation}
	\sigma_g=C_F\,g_s^2\int\frac{d^3\vec{k}}{2E_g((2\pi)^3}\Theta(E_g)\frac{2p_1p_2}{(p_1k)(p_2k)}=\frac{2\alpha_sC_F}{\pi}\int\frac{dE_g}{E_g}\frac{d\phi}{2\pi}\frac{d\theta}{\sin\theta}\,.
	\label{eq:g-cross-section}
\end{equation}
The angle $\theta$ is between the gluon and the quark (or anti-quark, depending on which is emitting the gluon) and $\phi$ is the angle in the out-of-page direction. \emph{18/09/2024 Note that equation~\eqref{eq:qqg-cross-section} is essentially like saying that the probability of an emission of a soft gluon from a hard emitter is given by the product of the LO $q\bar{q}$ production probability and the soft emission probability shown in equation~\eqref{eq:g-cross-section}}. The soft emission probability shows that there are singularities as the gluon becomes soft ($E_g\rightarrow0$) and when the gluon becomes collinear to the emitting quark (or anti-quark) ($\theta\rightarrow0,\pi$).
These are the IRC divergences talked about previously, and will arise for every gluon emission and therefore at every order in perturbation theory. When fully integrated (using dimensional regularisation to regulate the integrals), we obtain values proportional to $\frac{1}{\epsilon^2}$,  coming from the region where the gluon is soft and collinear, and terms proportional to $\frac{1}{\epsilon}$, which occur due to the gluon being only collinear to the quark (or antiquark). 
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{feynman}
            % Define vertices
            \vertex (a) {\(\gamma\)};
            \vertex [right=of a] (b);
            \vertex [above right=of b] (f1) {\(q\)};
            \vertex [below right=of b] (f2) {\(\overline{q}\)};
            \vertex at ($(f1)!0.5!(b)$) (mid1);
            \vertex at ($(f2)!0.5!(b)$) (mid2);
            
            % Draw diagram
            \diagram* {
                (a) -- [photon] (b),
                (b) -- [fermion] (f1),
                (b) -- [anti fermion] (f2),
                (mid1) -- [gluon] (mid2),
            };
        \end{feynman}
    \end{tikzpicture}
    \caption{NLO virtual diagram for $\gamma\rightarrow q\bar{q}g$.}
    \label{fig:photon-qq-gluon}
\end{figure}
The diagrams in figures \ref{fig:photon-qg} and \ref{fig:photon-bar-qg}, show the emission of a real gluon and therefore are termed real diagrams. In pQCD, it mandatory for us to include all diagrams which are allowed at a given order, and so we must also consider the diagram where there is a virtual gluon emitted and received between the quark-antiquark pair as depicted in figure \ref{fig:photon-qq-gluon}. We find that the cross-section of this process also contains divergences, and are equal and opposite to those which come from the real NLO processes. Therefore, we find a finite result when computing the overall cross-section at NLO \cite{Schwartz:2014sze}, \cite{Luisoni:2015xha}. We will state again for emphasis that this only occurs when the gluon is soft ($E_g\ll E_q,E_{\bar{q}}$). Next, we will see whether this behaviour occurs for other observables, beyond the cross-section. \emph{18/09/2024 It is important to note that it is the KLN theorem which states that the cancellation of IRC divergences between real and virtual diagrams occur at every order in perturbation theory provided that we sum over all possible virtual and final states.}



\section{High-energy physics}
\emph{Include: factorisation at high-energy limit, what a jet is, the process following a high-energy collision, IRC Safety, resummation requirement.}
{\color{green} Add in the big picture thing that is used in every single thesis here I think.}
\subsection{IRC Safety} 
\label{sec: IRC}
The cross-section falls into a category of inclusive observables. For such observables, the soft and collinear divergences cancel completely between the real and virtual diagrams in the IR limit (where $E_g\ll E_q,E_{\bar{q}}$) \cite{Campbell:2017hsr}. Exclusive observables, on the other hand, contain singularities and therefore unphysical results. Therefore, in order to avoid the issue of infinities we must define these to be IRC safe observables, which ensure the divergences cancel \cite{Luisoni:2015xha}, \cite{McAslan:2017bqp}, \cite{Arpino:2020smn}. \\ \\
An IRC safe observable is one that does not change regardless of the number of soft or collinear emissions, such that it obeys the following:
\begin{equation}
V(\{q\},k_1,\cdots ,k_n)=V(\{q\},k_1,\cdots , k_{j+1},\cdots ,k_n),\quad \text{when}\quad E_{j+1}\rightarrow0\quad\text{or}\quad\vec{k}_{j+1}\parallel \vec{q}_{\text{emit}}
	\label{eq:IRC-safety}
\end{equation}
where $V$ is the observable in question, $\{q\}$ are the hard partons, $k_{j+1}$ is the additional emission and ${q}_{\text{emit}}$ is the parent parton which emits the additional gluon. While equation~\eqref{eq:IRC-safety} holds for a single emission, the above must be true for any number of emissions. Therefore, IRC safe observables can be calculated to all orders in perturbation theory.




\section{Jet Physics}
{\color{RoyalBlue}
Jets are among the most frequently observed objects in proton–proton collisions at the LHC. They appear as highly collimated sprays of hadrons resulting from the hadronisation of energetic quarks and gluons produced in high-energy processes~\cite{Banfi:2016yyq}. When a hard parton is created in a short-distance interaction, it radiates gluons in a similarly collimated pattern along its initial direction. These gluons can in turn branch into further gluons or quark–antiquark pairs~\cite{Schwartz:2014sze}. As the radiation proceeds, the typical energy scale of the process decreases and the interactions between the partons become stronger, until they reach an energy of order $\Lambda_{\mathrm{QCD}}$. At this stage, the partons cluster together to form the final-state hadrons observed in the detector. These hadrons tend to group into fairly energetic, collimated clumps - known as \emph{jets}~\cite{Schwartz:2014sze, Campbell:2017hsr, Banfi:2016yyq}.
}




\subsection{Jet Definition}
{\color{RoyalBlue}
As described above, jets are complex, messy, and inherently ambiguous objects. To be able to describe them in a well-defined and reproducible way, we must introduce a \emph{jet definition}, which consists of the following components~\cite{Salam:2010nqg}:
\begin{enumerate}
\item a \emph{jet algorithm}: a systematic procedure for grouping final-state particles into jets and determining the number of jets present in an event, i.e.\ a set of rules that cluster particles into a given jet;
\item the algorithm's \emph{parameters}: these specify the proximity required between two particles for them to be recombined into a single entity belonging to the same jet;
\item a \emph{recombination scheme}: this defines how the momenta of two particles are combined to form the momentum of the new clustered particle — the most commonly used being the $E$-scheme, , which is a four-momentum sum, i.e.\ $p_i^\mu + p_j^\mu = p_k^\mu$.
\end{enumerate}
In the next subsection, we discuss the jet algorithm and its input parameters in more detail. }

\subsection{Jet Algorithm}
{\color{RoyalBlue}
In 1990, there was significant discussion within the high-energy physics community about how jets should be properly defined. To address this, a group of physicists formulated a set of requirements that a well-defined jet algorithm should satisfy, outlined in a document known as the \emph{Snowmass Accord}~\cite{Huth:1990mi}. The criteria are as follows:
\begin{enumerate}
    \item Simple to implement in an experimental analysis;
    \item Simple to implement in a theoretical calculation;
    \item Defined at any order in perturbation theory;
    \item Yields a finite cross section at any order in perturbation theory;
    \item Yields a cross section that is relatively insensitive to hadronisation effects.
\end{enumerate}
IRC safety ensures that jets defined at the detector, hadron, and parton levels are essentially equivalent, thereby satisfying the final three requirements outlined above. For IRC-safe observables, the effects of hadronisation are suppressed by inverse powers of the energy scale used in the process. Consequently, at higher energies, the correspondence between hadronic and partonic observables becomes increasingly accurate~\cite{Banfi:2016yyq}.
Overall, these requirements allow us to to regard jets as well-defined objects whose properties can be either determined by their constituent hadrons or underlying partons. This enables direct comparison between experimental measurements and theoretical calculations at the parton level. \\ \\
A wide variety of jet algorithms exist, each with its own advantages and limitations. The choice of algorithm depends on the specific physics question being addressed and the type of information one seeks to extract from an event. In general, jet algorithms can be divided into two broad classes: \emph{sequential recombination algorithms} and \emph{cone algorithms}~\cite{Banfi:2016yyq},~\cite{Salam:2010nqg}.
\begin{itemize}
    \item \textbf{Cone algorithms:} These group particles within a fixed radius $R$ in $(\eta,\phi)$ space, such that the particles whose transverse energy deposits fall inside the circular region are clustered into a jet. In three dimensions, these regions appear as cones. Different implementations vary in how they search for and define these cones. Cone algorithms are often described as \emph{top-down} algorithms.

    \item \textbf{Sequential recombination algorithms:} These iteratively cluster the closest particles according to a chosen distance measure until a stopping criterion is reached. Variations arise from different definitions of the distance measure (e.g.\ relative transverse momentum or angular separation between particles) and from the choice of stopping condition. Sequential recombination algorithms are often referred to as \emph{bottom-up} algorithms.
\end{itemize}
In this thesis, we focus exclusively on sequential recombination algorithms. The following sections discuss several of these algorithms to provide background for the new DIS algorithm introduced in Chapter~\ref{chapter: DIS}. For a comprehensive review of jets and jet algorithms across different processes, see Ref.~\cite{Salam:2010nqg}.
}

\subsection{Jet Algorithms for $e^+e^-$ Collisions}
\label{subsec: e+e-}
{\color{RoyalBlue}
Jet algorithms for electron–positron collisions follow a common iterative clustering procedure. Each pair of particles is assigned a \emph{distance measure}, $d_{ij}$, which determines how closely they are related. The closest pair is iteratively recombined until all remaining objects are separated by more than the chosen \emph{resolution parameter}, $d_{\mathrm{cut}}$.
This framework forms the basis of the JADE and Durham algorithms, while the Cambridge algorithm extends it by introducing an additional \emph{ordering variable}, $v_{ij}$, as discussed in the following sections.

\subsubsection{The JADE algorithm}
The first sequential recombination algorithm was introduced by the JADE Collaboration in 1988~\cite{JADE:1988xlj} and is defined as follows:
\begin{enumerate}
    \item \textbf{Define a resolution parameter} $d_{\mathrm{cut}}$.
    \item \textbf{Compute the distance measure} for every pair of particles $i$ and $j$:
    \begin{equation}
        \label{eq:yij-jade}
        d^{\mathrm{JADE}}_{ij} = \frac{2E_iE_j(1 - \cos\theta_{ij})}{Q^2}\,,
    \end{equation}
    where $Q$ is the total centre-of-mass energy, $E_i$ is the energy of particle $i$, and $\theta_{ij}$ is the angle between particles $i$ and $j$.
    \item \textbf{Identify the smallest $d_{ij}$ value.} If this minimum satisfies $d_{ij} < d_{\mathrm{cut}}$, the two particles are recombined into a pseudo-particle according to the chosen recombination scheme.
    \item \textbf{Repeat the procedure} from step 2 until all remaining pairs satisfy $d_{ij} > d_{\mathrm{cut}}$. The remaining objects are then defined as jets.
\end{enumerate}
A drawback of the JADE algorithm is its tendency to cluster soft pairs of gluons that are widely separated in angle. This can lead to situations where a hard parton is incorrectly merged with a soft gluon that was not emitted from it. Physically speaking, a jet should constitute to a hard parton together with its associated radiation, so such clustering is undesirable. This issue is resolved by modifying the distance measure, leading to the $k_\perp$ algorithm.
}


\subsubsection{ The $k_\perp$ (Durham) algorithm}
{\color{RoyalBlue}
Also known as the Durham algorithm~\cite{Catani:1991hj}, this approach follows the same procedure as JADE but employs a modified distance measure:
\begin{equation}
	 \label{eq:yij-De}
    	d^{\mathrm{Durham}}_{ij}=\frac{2(1-\cos\theta_{ij})}{Q^2}\min(E_i^2,E_j^2)\,.
\end{equation} 
At small angles, the numerator can be approximated to $(\min(E_i,E_j)\theta_{ij})^2$, which corresponds to the squared relative transverse momentum of particle $i$ with respect to particle $j$ (for $E_i < E_j$). The use of the $\min$ function ensures that soft emissions, widely separated in angle, have a larger distance measure than those corresponding to a hard parton radiating a nearby soft gluon. This modification prevents unphysical clustering of unrelated soft particles and produces jets that more accurately reflect the underlying partonic structure.
}
\subsubsection{The Cambridge algorithm}
{\color{RoyalBlue}
The Cambridge algorithm, first introduced in Ref.~\cite{Dokshitzer:1997in}, extends the Durham algorithm by employing angular ordering rather than transverse-momentum ordering. Unlike the previous two algorithms, it introduces an additional \emph{ordering variable}, $v_{ij}$, used alongside the distance measure $d^{\mathrm{Durham}}_{ij}$ from the Durham algorithm:
\begin{enumerate}
    \item \textbf{If only one particle remains,} stop the clustering and define this object as a jet.
    \item \textbf{Find the smallest $v_{ij}$} among all pairs of particles:
    \begin{equation}
        \label{eq:vij-cambridge}
        v_{ij} = 2(1 - \cos\theta_{ij})\,.
    \end{equation}
    \item \textbf{Identify the corresponding $d_{ij}$ value.} If $d_{ij} < d_{\mathrm{cut}}$, recombine the particles as in the Durham algorithm and return to step 1.
    \item \textbf{Otherwise,} remove the less energetic particle, label it as a jet, and return to step 1.
\end{enumerate}
This clustering procedure effectively reconstructs the sequence of gluon emissions in reverse, which typically occur at progressively smaller angles~\cite{Banfi:2016yyq}. As a result, the Cambridge algorithm is a better algorithm for the resolution of jet substructure and for reducing non- perturbative effects, which occur since emissions widely separated in angles are emitted independently from the hard legs. 
}
{\color{red} (Not understanding why this will give rise to better substructure and reduced NP effects.) }

\subsection{Jet Algorithms for Deep-Inelastic Scattering}
{\color{RoyalBlue}
 Deep-inelastic scattering (DIS) is the process:
\begin{equation}
    e^-(k) + N(P) \rightarrow e^-(k') + X(p_X)\,,
\end{equation}
where $N$ denotes the incoming hadron (usually a proton) and $X$ represents all final-state hadrons produced. In DIS processes, three lorentz invariants are often used to describe the kinematics:
\begin{equation}
\begin{aligned}
Q^2=-q^2\,, \qquad x=\frac{Q^2}{2P\cdot q}\,, \qquad y=\frac{P\cdot q}{P\cdot k}\,,
\end{aligned}
\end{equation}
where $Q^2$ is the virtuality of the photon, $x$ is the Bjorken $x$ variable (fraction of momentum taken by the struck quark from the the incoming hadron), and $y$ is the energy transferred between leptonic and hadronic systems~\cite{Devenish:2004pb}.  {\color{blue}(Need to get some more information on invariants (particularly $y$.)}
 \\ \\
At LO, the process produces a single outgoing parton in its final hadronic state:
\begin{equation}
    e^-(k) + N(P) \rightarrow e^-(k') + p_{\mathrm{out}}(p')\,.
\end{equation}
DIS processes are often analysed in the \emph{Breit frame}, defined as the reference frame in which the exchanged virtual photon carries no energy component, with four-momentum $q^{\mu} = (0, 0, 0, -Q)$. In this frame $P^{\mu} = p^{\mu}/x$, where  $ p^{\mu}$ is the momentum of the incoming parton, $p_{\mathrm{in}}$. In the Breit frame, the momenta of the incoming and outgoing partons are:  
\begin{equation}
\begin{aligned}
    p^{\mu} &= \frac{Q}{2}(1, 0, 0, +1)\,, \qquad
    p'^{\mu} = \frac{Q}{2}(1, 0, 0, -1)\,.
\end{aligned}
\end{equation}
In this frame, the proton and the virtual photon collide head-on, providing a clear separation between the incoming proton and the struck quark.\\ \\
 The presence of an initial-state hadron requires a modification of the $e^+e^-$ jet algorithms described previously to account for the incoming beam. In sequential recombination algorithms, this can be achieved by introducing an additional quantity, the \emph{beam distance}, $d_{iB}$~\cite{Salam:2010nqg}
\footnote{In hadron–hadron collisions, two beam distances are defined, $d_{iB}$ and $d_{i\bar{B}}$, corresponding to the two incoming beams.}.} \\ \\
{\color{blue} (I think we need some information on the variables i.e. $x$, $y$, and $Q^2$, along with a few images of the lab frame DIS and the Breit frame DIS, and also some information on TFR and CFR.)}


\subsubsection{$k_\perp$ DIS Algorithm}
{\color{RoyalBlue}
As introduced in Ref.~\cite{Catani:1992zp}, the $k_\perp$ algorithm described in Section~\ref{subsec: e+e-} was extended to DIS. The procedure is defined in the Breit frame and is performed in two stages. The aim is to first cluster all particles into a \emph{beam jet} and  \emph{final-state macro-jets}, and then to resolve the jet sub-structure within the latter.
\begin{enumerate}
    \item \textbf{Pre-clustering into beam jet and macro-jets}
    \begin{enumerate}
        \item Define a hard-scattering scale, $E_t$, such that $E_t^2 \gg \Lambda_{\mathrm{QCD}}^2$.
        \item For each particle $i$, compute the beam distance:
        \begin{equation}
        \label{eq:DIS-durham-diB}
            d_{iB} = \frac{2E_i^2(1 - \cos\theta_{iB})}{E_t^2}\,,
        \end{equation}
        where $\theta_{iB}$ is the angle between particle $i$ and the beam (initial-state proton) direction.

        \item Compute the distance measure for every pair of particles $i$ and $j$:
        \begin{equation}
        \label{eq:DIS-durham-dij}
            d_{ij} = \frac{2(1 - \cos\theta_{ij})}{E_t^2}\min(E_i^2, E_j^2)\,.
        \end{equation}

        \item Identify the smallest value among $\{d_{ij}, d_{iB}\}$:
        \begin{itemize}
            \item If $d_{ij} < 1$ and is the smallest, combine $(p_i, p_j)$ into a pseudo-particle $p_{ij}$, using the $E$-scheme recombination scheme.
            \item If $d_{iB} < 1$ and is the smallest, assign $p_i$ to the beam jet.
        \end{itemize}
        \item Repeat the procedure iteratively from step~(b) for all particles and pseudo-particles not yet assigned to the beam jet, until all remaining objects satisfy $d_{ij}, d_{iB} > 1$. The result is a final set of clustered objects consisting of a beam jet and final-state macro-jets. {\color{red}(I am unsure what happens to the particles which are greater than 1. I think they are just macrojets. I am also unsure if there is 1 or multiple macrojets)}
    \end{enumerate}

    \item \textbf{Resolving the jet structure of the macro-jet}
    \begin{enumerate}
        \item Define a resolution parameter, $d_{\mathrm{cut}}$.
        \item For each particle within the final-state macro-jet, evaluate the distance measures $d_{ij}$ and apply the same clustering procedure as the $k_\perp$ algorithm for $e^+e^-$ annihilation, described in Section~\ref{subsec: e+e-} to the final-state macrojet.
    \end{enumerate}
\end{enumerate}
}


\subsubsection{Cambridge DIS Algorithm}
This was originally proposed in~\cite{Wobisch:1998wt} and was an extension of the $e^+e^-$ Cambridge algorithm, introduced in Section~\ref{subsec: e+e-}, extended in the same way that the $k_\perp$ algorithm for  $e^+e^-$ was extended to DIS in the above.







